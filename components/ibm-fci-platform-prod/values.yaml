global:

  persistence:
    # This field can always be left blank because when running the cpd
    # installer, the storage class is provided using the -c command line
    # option, which overrides this setting.
    storageClassName: ''

    # By default, installation assumes that there is a dynamic provisioner
    # that allocates persistent volues using the storageClassName provided
    # above.
    #
    # If a dynamic provisioner is not in use, change useDynamicProvisioning
    # to false and if appropriate, set createPv to true.
    useDynamicProvisioning: true

  # createPv should be left false in cases where the PVs are auto-provisioned
  # or precreated by an administrator.  However, it's possible to use an NFS
  # server, set global.nfsServer to the value, and then set createPv to true,
  # and when installing the chart, the PVs will be created automatically using
  # the NFS Server.  Note that the NFS server must support NFS v4.1 or later.
  createPv: false

  # In some cases, when persistent volumes are created, the filesystem is
  # in a state where the pods will not have permission to write files to the
  # filesystem because they do not have permission.  This is often (but not
  # always) the case with auto-provisioners.
  # Setting this to true will create an initContainer that will run with
  # root-level priviledges in order to mount the volume, fix the filesystem
  # permissions, and then terminate.  If the PVs that are allocated already
  # have appropriate permissions, this field may be set to false.
  pvRequiresPermissionsFix: true

  # runAsUser is the user id that containers requiring updates to file system permissions
  # run as if pvRequiresPermissionsFix is set to true
  runAsUser: 1000

  # Provide the subdomain of the host used to access the cluster for
  # HTTP/HTTPS traffic.  This often can be determined by running this command:
  # oc get route console -n openshift-console | grep -v 'HOST/PORT' | awk '{print $2}'
  # This provides the URL of the OpenShift console.  After removing the
  # hostname up to the first dot, the remaining value will be the subdomain
  # required here.  For example, if the output of the command is:
  # console-openshift-console.apps.fyrecluster.os.fyre.ibm.com
  # then enter `apps.fyrecluster.os.fyre.ibm.com` here.
  # Or type this command
  # oc get route console -n openshift-console | grep -v 'HOST/PORT' | awk '{print $2}' | cut -d'.' -f 2-
  # which should give you `apps.fyrecluster.os.fyre.ibm.com`
  # If unsure, verify with the administrator that configured the OpenShift
  # cluster.  There can be a hardware loadbalancer in front of the cluster
  # making it impossible to determine the correct URL automatically.
  httpsIngressSubdomain: localhost.localdomain

  # Provide the subdomain of the host used to access the cluster for TCP/IP
  # traffic.  This is much more difficult to determine automatically.  In
  # some cases, this is the same as the httpsIngressSubdomain.  In other
  # cases, this could be a different value.  For example, in IBM Cloud (ibm.com/cloud),
  # the correct value for this can be determined by running this command:
  # oc get cm -n kube-system ibm-cloud-cluster-ingress-info -o yaml | grep ' ingress-subdomain'
  # which may output a value like:
  # sl-roks-441333-2ff4384e3bbe791290bc084e4f9f6c9a-0000.tor01.containers.appdomain.cloud
  # If unsure, verify with the administrator that configured the OpenShift
  # cluster.  There can be a hardware loadbalancer in front of the cluster
  # making it impossible to determine the correct URL automatically.
  tcpIngressSubdomain: localhost.localdomain

  # At this time, DB2 instances must be set to 1
  db2Instances: 1

  # generateInternalPasswords determines whether secrets for internal
  # services are randomly generated.  Set to false to use a pre-existing
  # secret instead of randomly generated values.  In this case, all
  # values must be precreated for all secrets.  See the knowledge center
  # for a list of all of the secrets and the keys that need to be created.
  generateInternalPasswords: true

  # externalSecretName is the name of the OpenShift secret object that
  # contains passwords to external services, such as LDAP.  This value
  # does not normally need to be changed.
  externalSecretName: fci-platform-external-secrets-env

  # hostAliases provides a way to manage /etc/hosts in all Kubernetes
  # pods that will be installed in the Kubernetes cluster.
  # This is useful in situations where DNS may not work properly,
  # or DNS entries are not used at all.  Most often, this is used
  # to add the Hadoop (HDP) servers into the /etc/hosts of each pod to
  # ensure that pods can resolve the HDP servers to the correct IP
  # addresses.
  #
  # In addition if you are using this because of DNS issues
  # you most likely would need to create /etc/hosts entries on the
  # nodes (hosts) that are running Kubernetes (the Kubernetes Master
  # and Kubernetes Worker nodes) to contain the hostnames and ip
  # addresses of the Hadoop servers (nodes).
  #
  # Below are examples with hostnames of hdp1, hdp2, hdp3
  # and the dns of the servers end in .yourcompany.com
  # If you have 6 HDP servers then follow the pattern below
  # and enter ip and hostnames for 6 servers
  #
  # Also uncomment all the lines below for this to take affect
  #
  # hostAliases:
  # - ip: "10.187.45.4"
  #   hostnames:
  #   - "hdp1.yourcompany.com"
  # - ip: "10.187.45.38"
  #   hostnames:
  #   - "hdp2.yourcompany.com"
  # - ip: "10.187.45.37"
  #   hostnames:
  #   - "hdp3.yourcompany.com"


  swidtag:
    # Indicate license used for this installation.
    # For production use, set file to: ibm.com_IBM_Cloud_Pak_for_Data_Financial_Crimes_Insight-6.5.1.swidtag
    # For non-production use, set file to: ibm.com_IBM_Cloud_Pak_for_Data_Financial_Crimes_Insight_for_Non-Production_Environment-6.5.1.swidtag
    # For FCI for Watson Private use, set file to: ibm.com_IBM_Financial_Crimes_Insight_with_Watson_Private-6.5.1.swidtag
    file: 'ibm.com_IBM_Cloud_Pak_for_Data_Financial_Crimes_Insight_for_Non-Production_Environment-6.5.1.swidtag'

##########################################################################
###
### With a few exceptions around specific components, not many fields
### need to be modified below here.  An example of where a number
### of changes are required would be to enable an LDAP server in
### security-auth section or enabling/disabling individual components.
###
##########################################################################

  commonScripts:
    image:
      repository: ibmcom/fci-common-scripts
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

  nginxSslProxy:
    image:
      repository: ibmcom/fci-nginx-ssl-proxy
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    resources:
      limits:
        cpu: 100m
        memory: 64Mi
      requests:
        cpu: 100m
        memory: 64Mi

  # SMTP Authentication to use for email alerting. Refer alertmanagerConfig and elastalertConfig further down this file
  smtp_auth_username: "<string>"
  smtp_auth_password: "<secret>"

  # The type of LDAP server being used.
  # Options include 'msad', 'sds', 'open', or 'none' (Keep the ' around the value)
  # msad -- Microsoft Active Directory
  # sds -- IBM Security Directory Server, formerly known as Tivoli Directory Server
  # open -- OpenLDAP
  # none -- no LDAP server, use basic registry instead
  # appid -- to enable authentication through IBM Cloud App ID service
  IDENTITY_SERVER_TYPE: 'msad'

  LDAP_SERVER_HOST: '<hostname>'
  LDAP_SERVER_PORT: '636'

  # set to True if connecting to the LDAP server over SSL
  # set to False otherwise
  LDAP_SERVER_SSL: True

  # The user account to connect (bind) to the LDAP server
  # For IBM Security Directory Server this is often 'cn=bind'
  LDAP_SERVER_BINDDN: 'administrator'

  # The LDAP_SERVER_SEARCHBASE is often referred to as the Base DN
  LDAP_SERVER_SEARCHBASE: 'cn=users,dc=aml,dc=ibm,dc=com'
  LDAP_PROFILE_DISPLAYNAME: 'displayName'
  LDAP_PROFILE_EMAIL: 'userPrincipalName'
  LDAP_PROFILE_GROUPS: 'memberOf'
  LDAP_PROFILE_ID: 'sAMAccountName'
  LDAP_PROFILE_TENANTS: 'fciTenants'
  LDAP_SERVER_USERNAME_MAPPING: 'sAMAccountName'

  # These are the default user search filters:
  # for Microsoft Active Directory: objectcategory=user
  # for IBM Security Directory Server: objectclass=inetOrgPerson
  # for OpenLDAP: objectClass=inetOrgPerson
  # If using a custom LDAP user search filter, uncomment this property and enter the filter as the value.
  #LDAP_USER_FILTER_OVERRIDE: 'objectclass=ePerson'

  # Performs a nested group search.
  # Set to true only if the LDAP server does not support recursive server-side searches.
  LDAP_SERVER_RECURSIVE_SEARCH: 'false'

  # Set the Additional Group ID settings that the containers should run as
  # This depends on the GID of the shared storage like NFS
  fsGroupConfig:
    supplementalGroups:
    - 0

  hdp:
    # If using a non-prod HDP topology do two things to configure the HDP_NAME_NODE
    # i) uncomment the line below and provide HDP_MASTER_NODE (just delete the #)
    #HDP_NAME_NODE: 'hdfs://<HDP_MASTER_NODE>:8020'
    # ii) comment out the other line HDP_NAME_NODE: 'hdfs://fcicluster'

    # If using the HDP production environment, leave the line below as is. For HDP dev env. & single server comment it out
    HDP_NAME_NODE: 'hdfs://fcicluster'

    # Set to the fully qualified domain name of the HDP master node.
    HDP_MASTER_NODE: 'HDP_MASTER_FQDN'

    # If using the HDP production environment, make sure to set to the fully qualified domain name of the HDP secondary master node.
    HDP_SECONDARY_MASTER_NODE: 'HDP_SECONDARY_MASTER_FQDN'

    # Set to the fully qualified domain name of the HDP Ambari server.
    HDP_AMBARI_NODE: 'AMBARI_FQDN'

  kerberos:
    # This value should not be changed.
    KERBEROS_REALM: 'FCI.IBM'

    KINIT_SECONDS: '3600'
    HADOOP_VERSION: '3.x'
    HDP_CLUSTER_NAME: 'fcicluster'
    KERBEROS_ENABLED: 'true'

    runAsUser: 1000
    resources:
      requests:
        memory: "64Mi"
        cpu: ".1"
      limits:
        memory: "512Mi"
        cpu: ".5"


  hbase:
    # For the hbase_zookeeper_quorum property, you must specify at least one zookeeper
    # server. For a 6 server hdp install (prod topology)  Zookeeper servers are: HDP Master Node.
    # HDP Gateway and HDP Secondary Master. For 3 server hdp install (dev topology) the Zookeeper servers are:
    # HDP Master and HDP Gateway. For single server hdp install the Zookeeper server is the HDP Hostname.
    # Do not inlcude the <> in the hostname.  For example
    # hbase_zookeeper_quorum: 'hdp-master.acme.com,hdp-gw.acme.com,hdp-2gw.acme.com'
    hbase_zookeeper_quorum: '<ZOOKEEPER_SERVER_1,ZOOKEEPER_SERVER_2,ZOOKEEPER_SERVER_N>'
    hbase_zookeeper_property_clientPort: '2181'

  commonUI:
    # For ROKS and CP4D releases, add full hostname (subdomain of the ingress subdomain) of fci-common-ui-nginx route for http traffic
    SSO_HOSTNAME: "<roks_subdomain>"
    # Prior releases to 6.5, keep this to 3000 for the security-auth service port.
    SSO_PORT: "443"

db2:
  hostIPC: true
  # Select antiAffinity as either hard or soft
  podAntiAffinity: hard

  nodeSelector: {}

  resources:
    requests:
      memory: "5Gi"
      cpu: "0.5"
    limits:
      memory: "32Gi"
      cpu: "8"

  # Load Balancer Node Ports - Ports to expose in load balancer for CP4D installs
  # Set to an empty string to use a random port
  sslNodePort: "30560"

  image:
    repository: ibmcom/fci-data-store-server
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

  instancePvcSpec:
    accessModes:
      - ReadWriteOnce
    storageClassName: null
    size: 1Gi

  dbPvcSpec:
    accessModes:
      - ReadWriteOnce
    storageClassName: null
    size: 100Gi

  scriptsPvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 1Gi

global-name-mgmt:
  enabled: false

  image:
    repository: ibmcom/fci-global-name-mgmt
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

kafka:
  # Set to False to disable Kafka in a non-production environment
  enabled: True

  # A cluster of three Kafka and Zookeeper instances is created by default.
  # In a non-production environment, a cluster of one Kafka and Zookeeper instances can be used by setting replicas to 1.
  replicas: 3
  zookeeperReplicaCount: 3

  pvcSpec:
    storageClassName: null
    size: 10Gi

  image:
    repository: ibmcom/fci-kafka
    tag: "<BUILD_TAG>"
    pullPolicy: "IfNotPresent"

  ## Topic creation and configuration.
  ## The job will be run on a deployment only when the config has been changed.
  ## - If 'partitions' is specified we create the topic (with --if-not-exists.)
  ## - If 'partitions' is specified we 'alter' the number of partitions. This will
  ## silently and safely fail if the new setting isn't strictly larger than the old (i.e. a NOOP.) Do be aware of the
  ## implications for keyed topics (ref: https://docs.confluent.io/current/kafka/post-deployment.html#admin-operations)
  ## - If 'defaultConfig' is specified it's deleted from the topic configuration. If it isn't present,
  ## it will silently and safely fail.
  ## - If 'config' is specified it's added to the topic configuration.
  ##
  topics:
    - name: Party-General
      partitions: 1
    - name: Party-Match-Upload
      partitions: 1
    - name: Party-Resolved-Update
      partitions: 1
    - name: Party-Delete
      partitions: 1
    - name: FCI_IGA_AI_Data_Account
      partitions: 1
    - name: FCI_IGA_AI_Data_Transaction
      partitions: 1
    - name: FCDD_ML_CLASSIFIED
      partitions: 1
    - name: FCI_SEC_AuditRecords
      partitions: 1
    - name: sifs.email.in
      partitions: 10
      config: "retention.ms=86400000"
    - name: sifs.chat.in
      partitions: 10
    - name: sifs.alert.in
      partitions: 1
    - name: sifs.ecomm.in
      partitions: 10
    - name: sifs.voice.in
      partitions: 1
    - name: sifs.attach.in
      partitions: 10
      config: "retention.ms=86400000"

  ## Configuration Overrides. Specify any Kafka settings you would like set on the StatefulSet
  ## here in map format, as defined in the official docs.
  ## ref: https://kafka.apache.org/documentation/#brokerconfigs
  ## The end user does not need to edit any of these configurations
  configurationOverrides:
    "listener.security.protocol.map": "SSL:SSL,EXTERNAL:SSL"
    "inter.broker.listener.name": "SSL"
    "ssl.endpoint.identification.algorithm": ""

    # client authentication is requested, but a client without certs can still connect.
    # Change to "required" if client authentication is required.
    "ssl.client.auth": "requested"
    "confluent.support.metrics.enable": false
    "advertised.listeners": |-
     EXTERNAL://${MASTER_HOST}:${NODE_PORT}

  # First Listerner Port to hit the kafka externally.
  # Set to an empty string to use a random port
  nodeport:
    firstListenerPort: "31090"
  zookeeper:
    image:
      repository: ibmcom/fci-zookeeper
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    # The external port for Zookeeper.
    # Set to an empty string to use a random port
    externalNodePort: "32181"

    dataPvcSpec:
      storageClassName: null
      size: 10Gi

    logPvcSpec:
      storageClassName: null
      size: 10Gi

mongodb:
  enabled: True
  securityContext:
    enabled: false
  # If the customer has permanently disabled IPv6
  # (including for all kernel updates)
  # change this value to false so that mongodb will start.
  mongodbEnableIPv6: true

  pvcSpec:
    accessModes:
      - ReadWriteOnce
    storageClassName: null
    size: 10Gi

  image:
    repository: ibmcom/fci-mongodb
    tag: <BUILD_TAG>
    pullPolicy: IfNotPresent

elasticsearch:
  enabled: True

  config:
    ES_ADMIN_DN: "CN=FCI_server,OU=FCI_platform,O=FCI_Development,C=US"

    # Set the minimum heap size (Xms) and maximum heap size (Xmx) to be equal to each other.
    ES_JAVA_OPTS: "-Xmx1g -Xms1g"

    # The Elasticsearch user id is fci_admin
    # The number of minutes to wait until Elasticsearch starts.
    # If Elasticsearch has not started within this amount of time, then the Elasticsearch
    # container will be restarted.
    # Increase this value on systems with a slow disk.
    WAIT_MINUTES: '3'

  image:
    repository: ibmcom/fci-logsearch
    tag: "<BUILD_TAG>"
    pullPolicy: "IfNotPresent"

  # If upgrading from the 6.5 release, then change below to ReadWriteMany
  pvcSpec:
    accessModes:
    - ReadWriteOnce
    storageClassName: null
    size: 10Gi

odm:
  # set to False to disable ODM
  # set to True otherwise
  enabled: False

  dbClient:
    image:
      repository: ibmcom/fci-rms-odm-data-store
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

  odm:
    image:
      repository: ibmcom/fci-rms-odm
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    resources:
      requests:
        memory: "256Mi"
        cpu: "0.1"
      limits:
        memory: "8Gi"
        cpu: "3"

  config:
    FLYWAY_BASELINE_VERSION: '01.01.01.00.005'

wca:
  enabled: false

  pvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 30Gi

  image:
    repository: ibmcom/fci-wca
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

cognos:
  enabled: false

  image:
    repository: ibmcom/fci-cognos
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

  pvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 1Gi

  resources:
    requests:
      memory: "10Gi"
      cpu: "1"
    limits:
      memory: "16Gi"
      cpu: "4"

  config:
    # MAX_HTTP_HEADER_SIZE is the maximum size, in bytes, of HTTP headers that Cognos will allow
    # in HTTP requests
    MAX_HTTP_HEADER_SIZE: "8000"

  proxy:
    resources: {}
    image:
      repository: ibmcom/fci-dashboards-proxy
      tag: <BUILD_TAG>
      pullPolicy: "IfNotPresent"

crypto-utils:
  image:
    repository: ibmcom/fci-crypto-utils
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

  resources: {}

  # Make a note of the fully qualified domain name of your OpenShift nodes (master and workers)
  # for your installation.
  #
  # You MUST do one of the following.  Failure to do so will result in an installation failure.
  #
  # 1) Enter the values for CERT_DN, CERT_SAN_DNS_SPEC, and CERT_SAN_IP_SPEC.
  #    This generates new, replacement SSL keystore artifacts (including a new
  #    self-signed certificate).  This technique is often used for 'proof of concept' installations.
  #
  # 2) Obtain SSL/TLS certificates from a trusted certificate authority (CA)
  #    and configure the FCI according the documentation section called Managing SSL/TLS universal keystores.
  #    This technique is recommended for production installations.

  config:
    # REGENERATE_CERTS - this property determines if new, replacement universal SSL
    #                   keystore artifacts are generated.
    #
    #                   Valid values are: true -or- false.
    #
    #                   If true is specified, then confirm the certificate information
    #                   specified in the associated properties are correct for your
    #                   installation.
    #
    #                   If false is specified, then certificates will only be generated if
    #                   they do not already exist.
    REGENERATE_CERTS: false

    # SECRET_NAME is the name of the OpenShift secret object that contains the FCI
    # keystore artifacts.  This typically does not need to be changed.
    SECRET_NAME: 'platform-secret-files'

    # USER_SECRET_NAME is the name of the pre-defined secret that contains a user's
    # private key and certificate chain in PEM format.
    # The private key must be 'key.pem'.
    # The certificate chain must be 'crt.pem'.
    # If this secret exists and the FCI keystore secret has not been created already,
    # then the FCI keystore artifacts will be created from the key/certificate in this
    # pre-existing secret.
    # Enclose the values with ''
    USER_SECRET_NAME: 'fci-user-secret-files'
    # CERT_DN - use this property to set the Distinguished Name for the SSL
    #           certificate. This does not have to match up or have similar values
    #           for the CN or DN values of your LDAP (if your install specifies an LDAP server).
    #           Typically the default value below is fine for most installations.
    #
    #           Example: 'CN=FCI_server,OU=FCI_platform,O=FCI_Development,C=US'
    #
    CERT_DN: 'CN=FCI_server,OU=FCI_platform,O=FCI_Development,C=US'
    #
    # CERT_SAN_DNS_SPEC - use this property to set the DNS names to be
    #                     included in the certificate SubjectAlternativeName
    #                     extension.
    #
    #                     Run the following command to get the httpsIngressSubdomain
    #  oc get route console -n openshift-console | grep -v 'HOST/PORT' | awk '{print $2}' | cut -d'.' -f 2-
    #
    #                     The format is a comma-separated list of DNS names.
    #                     Wildcard domain specifications are acceptable.
    #                     There MUST BE no spaces before or after the comma in this list!!
    #                     This must include openshfit cluster information and hdp servers information
    #
    #                     You MUST have at least two entries for the OpenShift cluster
    #                     1) the full DNS name of your httpsIngressSubdomain (for example fciroute.yourco.com)
    #                     2) *.full DNS name of your httpsIngressSubdomain (for example *.fciroute.yourco.com)
    #                     If your https and tcp ingress are different you would have 4 entries for OpenShift
    #
    #                     Then you must include either the dns names for each HDP server or *.subdomain that includes
    #                     all HDP servers.  Specifying each HDP server indivdually is more secure as it limits only
    #                     those individual HDP servers to communicate to the openshift cluster
    #
    #                     For OpenShift include a wildcard for the subdomain and the domain itself (see example2 below)
    #
    #                     The localhost,127.0.0.1 at the end of this CERT_SANS_DNS_SPEC entry is optional
    #
    #                     Example1: CERT_SANS_DNS_SPEC = '*.localdomain,localdomain,localhost,127.0.0.1'
    #
    #                     Example2: The servers or virtual machines (nodes) for your install have
    #                     httpsIngressSubdomain that matches your tcpIngressSubdomain for an OpenShift 4.3.x install
    #                     the httpsIngressSubdomain is: fciroute.yourco.com
    #                     The Hadoop nodes have dns names like ambari.yourhdp.com, hdp1.yourhdp.com, hdp2.yourhdp.com
    #                     this line would need to look like either (note if all of your hdp machines are under
    #                     .yourhdp.com, you can simply use *.yourhdp.com, NOTE: your HDP machines must be directly under
    #                     .yourhdp.com for *.yourhdp.com to work, the HDP host cannot be hdp1.lab.yourhdp.com for example):
    #
    #                     CERT_SANS_DNS_SPEC = '*.fciroute.yourco.com,fciroute.yourco.com,*.yourhdp.com,localhost,127.0.0.1'
    #                     or
    # CERT_SANS_DNS_SPEC = '*.fciroute.yourco.com,fciroute.yourco.com,ambari.yourhdp.com,hdp1.yourhdp.com,hdp1.yourhdp.com,hdp2.yourhdp.com,localhost,127.0.0.1'
    #
    #                     Example3, same as Example 2 but the tcp ingress is tcpfciroute.yourco.com
    #                     everything else is the same as Example2 (this could be an OpenShift 3.11.x install)
    #
    # CERT_SANS_DNS_SPEC = '*.fciroute.yourco.com,fciroute.yourco.com,*.tcpfciroute.yourco.com,tcpfciroute.yourco.com,*.yourhdp.com'
    #
    CERT_SAN_DNS_SPEC: '*.localdomain,localhost,127.0.0.1'
    #
    # CERT_SAN_IP_SPEC - use this property to set IP addresses to be
    #                    included in the certificate SubjectAlternativeName
    #                    extension.
    #
    #                    Typically this line is a comma-separated list of IP addresses.
    #
    #                    Example: CERT_SAN_IP_SPEC = '127.0.0.1'
    #                    Typically this line is left unchanged.
    CERT_SAN_IP_SPEC: '127.0.0.1'
    # Set to false to generate unique certificates (recommended for production use)
    USE_DEFAULT_CERTS: false

logging:
  # set to False to disable logging infrastructure in a non-production environment
  enabled: True

  logstash:
    image:
      repository: ibmcom/fci-loganalysis
      tag: <BUILD_TAG>

  kibana:
    image:
      repository: ibmcom/fci-logvisualization
      tag: <BUILD_TAG>

security-audit:
  # set to False to disable auditing in a non-production environment
  enabled: True

  image:
    repository: ibmcom/fci-security-audit-app
    tag: <BUILD_TAG>
    pullPolicy: IfNotPresent

  config:
    FLYWAY_BASELINE_VERSION: '2019.02.28.13.59.00'

  db2:
    image:
      repository: ibmcom/fci-security-audit-data-store
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

security-auth:
  replicas: 2
  nodejs:
    resources: {}
    image:
      repository: ibmcom/fci-security-auth
      tag: '<BUILD_TAG>'
      pullPolicy: IfNotPresent
  redis:
    resources: {}
    image:
      repository: ibmcom/fci-memoryds
      tag: '<BUILD_TAG>'
      pullPolicy: IfNotPresent


  securityAuthConfig:
    # set to '0' to disable auditing in a non-production environment
    AUDIT_ACTIVE: '1'

    # Role definitions
    # Do not modify  the Role definitions below
    ROLE_ANALYST: 'analyst'
    ROLE_INVESTIGATOR: 'investigator'
    ROLE_SUPERVISOR: 'supervisor'
    ROLE_ADMIN: 'admin'
    ROLE_DATA_SCIENTIST: 'data_scientist'
    ROLE_EXECUTIVE: 'executive'
    ROLE_QUALITY_ASSURANCE: 'quality_assurance'
    ROLE_READ_ONLY: 'read_only'
    ROLE_CONFIDENTIAL: 'confidential'

    # UI configuration definitions
    # Do not modify the UI configurations below
    ROLE_SURVEILLANCE: 'si'
    ROLE_COMPLAINTS: 'si-complaints'
    ROLE_CASE_MANAGER: 'case_manager'
    ROLE_INSURANCE: 'insurance'
    ROLE_KYC: 'kyc'
    ROLE_GRAPH: 'graph'
    ROLE_ALERTS_INSIGHT: 'alerts_insight'
    ROLE_TOOLING: 'tooling'
    ROLE_TLS: 'tls'

    # Team definitions
    # NOTE: The team names must begin with TEAM_
    # These values can be changed but you must follow documentation
    # under the section called Changing Team Names (do a search for it in the
    # documentation). It is under topic Managing groups, roles, UI configurations, and teams
    TEAM_TRIAGE_TEAM: 'TriageTeam'
    TEAM_INVESTIGATION_TEAM: 'InvestigationTeam'
    TEAM_SUPERVISOR_TEAM: 'SupervisorTeam'
    TEAM_CONFIDENTIAL_TEAM: 'confidential'
    TEAM_VENDOR_TEAM: 'VendorTeam'
    TEAM_LEGAL_TEAM: 'LegalTeam'

    # Role groups
    GROUP_ANALYST: 'CN=analysts,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_INVESTIGATOR: 'CN=investigators,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_SUPERVISOR: 'CN=supervisors,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_ADMIN: 'CN=admins,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_DATA_SCIENTIST: 'CN=datascientists,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_EXECUTIVE: 'CN=executives,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_QUALITY_ASSURANCE: 'CN=qualityassurance,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_READ_ONLY: 'CN=readonly,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_CONFIDENTIAL: 'CN=confidential,CN=Users,DC=aml,DC=ibm,DC=com'

    # UI configuration groups
    GROUP_SURVEILLANCE: 'CN=surveillance,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_COMPLAINTS: 'CN=complaints,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_CASE_MANAGER: 'CN=casemanager,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_INSURANCE: 'CN=insurance,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_KYC: 'CN=kyc,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_GRAPH: 'CN=graph,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_ALERTS_INSIGHT: 'CN=alerts_insight,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_TOOLING: 'CN=tooling,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_TLS: 'CN=tls,CN=Users,DC=aml,DC=ibm,DC=com'

    # Team groups
    GROUP_TRIAGE_TEAM: 'CN=TriageTeam,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_INVESTIGATION_TEAM: 'CN=InvestigationTeam,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_SUPERVISOR_TEAM: 'CN=SupervisorTeam,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_CONFIDENTIAL_TEAM: 'CN=confidential,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_VENDOR_TEAM: 'CN=VendorTeam,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_LEGAL_TEAM: 'CN=LegalTeam,CN=Users,DC=aml,DC=ibm,DC=com'



    # specify internal user registry (also known as basic user registry) from WebSphere Liberty
    # for each numbered user, specify the user's id, roles, tenants, and password
    # roles are comma separated
    # tenants are comma separated
    # valid roles include: admin, analyst, investigator, supervisor, data_scientist
    # password are specified in the secrets.yaml file of the install toolkit
    # to add additional users, add additional user properties numbered 17, 18, etc.
    USER_ID_1: fciadmin
    USER_ROLES_1: admin,supervisor,investigator,analyst,data_scientist
    USER_TEAMS_1: SupervisorTeam,InvestigationTeam,TriageTeam
    USER_TENANTS_1: ibm.com
    USER_ID_2: fcianalyst
    USER_ROLES_2: analyst
    USER_TEAMS_2: TriageTeam
    USER_TENANTS_2: ibm.com
    USER_ID_3: fciinvestigator
    USER_ROLES_3: investigator
    USER_TEAMS_3: InvestigationTeam
    USER_TENANTS_3: ibm.com
    USER_ID_4: fcisupervisor
    USER_ROLES_4: supervisor
    USER_TEAMS_4: SupervisorTeam,InvestigationTeam,TriageTeam
    USER_TENANTS_4: ibm.com
    USER_ID_5: fcidatascientist
    USER_ROLES_5: data_scientist
    USER_TEAMS_5: InvestigationTeam
    USER_TENANTS_5: ibm.com
    USER_ID_6: fciconfidential
    USER_ROLES_6: confidential
    USER_TEAMS_6: confidential
    USER_TENANTS_6: ibm.com
    USER_ID_7: fciiadmin
    USER_ROLES_7: admin,insurance
    USER_TEAMS_7: SupervisorTeam,InsuranceTeam
    USER_TENANTS_7: ibm.com
    USER_ID_8: fciianalyst
    USER_ROLES_8: analyst,insurance
    USER_TEAMS_8: TriageTeam,InsuranceTeam
    USER_TENANTS_8: ibm.com
    USER_ID_9: fciiinvestigator
    USER_ROLES_9: investigator,insurance
    USER_TEAMS_9: InvestigationTeam,InsuranceTeam
    USER_TENANTS_9: ibm.com
    USER_ID_10: fciisupervisor
    USER_ROLES_10: supervisor,insurance
    USER_TEAMS_10: SupervisorTeam,InsuranceTeam
    USER_TENANTS_10: ibm.com
    USER_ID_11: tlsadmin
    USER_ROLES_11: admin,tls
    USER_TEAMS_11: SupervisorTeam
    USER_TENANTS_11: ibm.com
    USER_ID_12: fcaisupervisor
    USER_ROLES_12: alerts_insight,supervisor
    USER_TEAMS_12: TriageTeam
    USER_TENANTS_12: ibm.com
    USER_ID_13: fcaianalyst
    USER_ROLES_13: alerts_insight,analyst
    USER_TEAMS_13: TriageTeam
    USER_TENANTS_13: ibm.com
    USER_ID_14: fcaiinvestigator
    USER_ROLES_14: alerts_insight,investigator
    USER_TEAMS_14: TriageTeam
    USER_TENANTS_14: ibm.com
    USER_ID_15: fcaiadmin
    USER_ROLES_15: alerts_insight,admin
    USER_TEAMS_15: TriageTeam
    USER_TENANTS_15: ibm.com
    USER_ID_16: fcaiexecutive
    USER_ROLES_16: alerts_insight,executive
    USER_TEAMS_16: TriageTeam
    USER_TENANTS_16: ibm.com
    USER_ID_17: toolingadmin
    USER_ROLES_17: admin,data_scientist,tooling
    USER_TEAMS_17: SupervisorTeam
    USER_TENANTS_17: ibm.com
    USER_ID_18: graphadmin
    USER_ROLES_18: admin,supervisor,graph
    USER_TEAMS_18: SupervisorTeam
    USER_TENANTS_18: ibm.com
    USER_ID_19: sisupervisor
    USER_ROLES_19: si,si-complaints,supervisor
    USER_TEAMS_19: SupervisorTeam,InvestigationTeam,TriageTeam
    USER_TENANTS_19: ibm.com
    USER_ID_20: sianalyst
    USER_ROLES_20: si,analyst
    USER_TEAMS_20: TriageTeam
    USER_TENANTS_20: ibm.com
    USER_ID_21: siinvestigator
    USER_ROLES_21: si,investigator
    USER_TEAMS_21: InvestigationTeam
    USER_TENANTS_21: ibm.com
    USER_ID_22: siadmin
    USER_ROLES_22: si,admin
    USER_TEAMS_22: SupervisorTeam,InvestigationTeam,TriageTeam
    USER_TENANTS_22: ibm.com
    USER_ID_23: kycadmin
    USER_ROLES_23: admin,supervisor,investigator,analyst,data_scientist,kyc
    USER_TEAMS_23: SupervisorTeam,InvestigationTeam,TriageTeam
    USER_MAIL_23: kycadmin@ibm.com
    USER_DISPLAY_NAME_23: kycadmin
    USER_TENANTS_23: ibm.com
    USER_ID_24: fcilegal
    USER_ROLES_24: supervisor,insurance
    USER_TEAMS_24: LegalTeam
    USER_TENANTS_24: ibm.com
    USER_ID_25: fcivendor
    USER_ROLES_25: analyst,insurance
    USER_TEAMS_25: VendorTeam
    USER_TENANTS_25: ibm.com

    # JWT_KEY_EXPIRY is the length of time before the security token expires
    # This controls the length of a user's session after logging in.
    # The value is expressed in a time span. e.g.:  "30m", "4h", "1d"
    JWT_KEY_EXPIRY: '4h'
    # DO NOT CHANGE THIS VALUE:
    JWT_ISSUER: 'fci.ibm.com'

    #SAML configuration
    SAML_DISABLEREQUESTEDAUTHNCONTEXT: "true"
    # identity provider entrypoint
    # This is typically the URL provided by the identity provider for a user to log in
    SAML_ENTRY_POINT: 'https://<hostname>/adfs/ls'
    # name identifier format to request from identity provider
    SAML_IDENTIFIERFORMAT: 'urn:oasis:names:tc:SAML:1.1:nameid-format:unspecified'
    # issuer string to supply to identity provider
    SAML_ISSUER: 'https://<hostname>/adfs/services/trust'
    # the SAML profile property that maps to a user's display name
    SAML_PROFILE_DISPLAYNAMEPROP: 'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name'
    # the SAML profile property that maps to a user's email address
    SAML_PROFILE_EMAILPROP: 'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress'
    # the SAML profile property that maps to a user's groups
    SAML_PROFILE_GROUPSPROP: 'http://schemas.xmlsoap.org/claims/Group'
    # the SAML profile property that maps to a user's id
    SAML_PROFILE_NAMEIDPROP: 'nameID'
    # SAML_ACCEPTED_CLOCK_SKEW is the time in milliseconds of skew
    # that is acceptable between client and server
    # when checking OnBefore and NotOnOrAfter assertion condition validity timestamps.
    # Setting to -1 will disable checking these conditions entirely.
    SAML_ACCEPTED_CLOCK_SKEW: '5000'

    ### IBM Cloud AppID configuration ###
    ## You can find these configuration values by clicking View credentials
    ## in the 'Service credentials' tab of your AppID service's manage section.
    # The client ID for the App ID instance of service.
    APPID_CLIENT_ID: <clientId>
    # Tenant ID is specific to our App ID instance
    APPID_TENANTID: <tenantId>
    # The App ID oauth server URL which is used for redirecting user to IBM Cloud app ID based authentication.
    APPID_OAUTH_SERVER_URL: "https://us-south.appid.cloud.ibm.com/oauth/v4/<tenantId>"
    # The App ID profiles URL.
    APPID_PROFILES_URL: "https://us-south.appid.cloud.ibm.com"
    # The App ID API version.
    APPID_VERSION: "4"
    # End Point for the app ID service.
    APPID_SERVICE_ENDPOINT: "https://us-south.appid.cloud.ibm.com"
    # Default Call back URL needed for redirecting to security-auth service after AppID authentication.
    APPID_CALLBACK_URL: "/security-auth/ibm/cloud/appid/callback"
    # IBM Cloud IAM Token URL
    APPID_IAM_TOKEN_URL: "https://iam.cloud.ibm.com/identity/token"

    # BRUTE_THROTTLING is set to 'true' to enable throttling of requests from an IP address
    # when too many invalid logins have occurred from that IP address.
    # It is used to prevent brute force attacks.
    # Set to 'false' to disable this feature.
    BRUTE_THROTTLING: 'true'
    # BRUTE_FREE_RETRIES specifies the number of invalid logins before throttling begins
    BRUTE_FREE_RETRIES: '5'

    # MULTI_TENANCY_ENABLED enable multi-tenancy fields in JWT
    MULTI_TENANCY_ENABLED: 'true'
    # Default tenants to use if none provided by LDAP and MULTI_TENANCY_ENABLED is set to true
    DEFAULT_TENANT_IF_MISSING: 'ibm.com'

case-manager:
  # set to False to disable Case Manager
  # set to True otherwise
  enabled: True

  mq:
    # Load Balancer Node Ports - Port to expose in loadbalancer for CP4D installs
    # Set to an empty string to use a random port
    mqNodePort: "30683"
    mqSeriesNodePort: "30997"
    image:
      repository: ibmcom/fci-messaging
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    resources:
      requests:
        memory: "256Mi"
        cpu: ".5"
      limits:
        memory: "512Mi"
        cpu: "2"
    nodeSelector: {}
    tolerations: []
    affinity: {}
  liberty:
    image:
      repository: ibmcom/fci-solution
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    resources:
      requests:
        memory: "256Mi"
        cpu: "1"
      limits:
        memory: "9Gi"
        cpu: "4"
    nodeSelector: {}
    tolerations: []
    affinity: {}
    # runAsUser is the user id that containers requiring updates to file system permissions
    # run as if pvRequiresPermissionsFix is set to true
    runAsUser: 1000
  kerberosClient:
    image:
      repository: ibmcom/fci-hdp-client
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

  libertyConfig:
    env_fci_batch_userid: 'fcibatch'
    COM_FCI_HBASE_SITE_FILE: "/home/wlpadmin/hbase-site.xml"
    COM_FCI_CORE_SITE_FILE: "/home/wlpadmin/core-site.xml"
    COM_FCI_KRB5_CONF_FILE: "/home/wlpadmin/krb5.conf"

  solutionPvcSpec:
    accessModes:
    - ReadWriteMany
    storageClassName: null
    size: 1Gi

  # If upgrading from the 6.5 release, then change below to ReadWriteMany
  mqPvcSpec:
    accessModes:
    - ReadWriteOnce
    storageClassName: null
    size: 1Gi

cedm:
  # set to False to disable CEDM
  # set to True otherwise
  enabled: True

  liberty:
    image:
      repository: ibmcom/fci-cedm-integration
      tag: <BUILD_TAG>
    resources:
      requests:
        memory: "256Mi"
        cpu: "1"
      limits:
        memory: "12Gi"
        cpu: "4"
    # runAsUser is the user id that containers requiring updates to file system permissions
    # run as if pvRequiresPermissionsFix is set to true
    runAsUser: 1000
  kerberosClient:
    image:
      repository: ibmcom/fci-hdp-client
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

  db2:
    image:
      repository: ibmcom/fci-cedm-data-store-client
      tag: <BUILD_TAG>

  libertyPvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 30Gi

  cedmConfig:
    FLYWAY_BASELINE_VERSION: '01.01.01.00.119'

    #Kafka max message size in producer (Broker max message size - 1KB)
    KAFKA_MAX_REQUEST_SIZE: '19998988'

    # Publish batch size and frequency
    PARTY_PUBLISH_BATCH_SIZE: '250'
    PARTY_PUBLISH_PERIOD_SECONDS: '300'

    # HDP VERSION 2.6 or 3.1.0
    HDP_VERSION: '3.1.0'

    # Big Match Oozie Workflow Config
    OOZIE_MAX_JVM_HEAP_SIZE: '4712'

    OOZIE_NUM_OF_WORKER_TASKS: '4'
    # If using the HDP development environment, set the number of worker tasks to 2
    # If using a single HDP server, set the number of worker tasks to 1.
    #OOZIE_NUM_OF_WORKER_TASKS: '2'

    OOZIE_NUM_OF_THREADS_FOR_EACH_WORKER: '1'
    OOZIE_PORT: '11443'
    OOZIE_JOBTRACKER_PORT: '8050'
    OOZIE_SECURE_CONNECTION: 'true'
    # The Fully Qualified DNS Name (FQDN) of the Oozie server.  The Oozie server is the
    # Hadoop Master for both production topology (6 servers), dev topology (3 servers) and
    # single HDP server install.  Do not include the <> in the hostname
    OOZIE_SERVER: '<hostname>'
    OOZIE_USER_NAME: 'bigmatch'

    # If using the HDP development environment or HDP single server do two things to configure the HDP_NAME_NODE
    # i) uncomment the the line below and provide HDP_MASTER_NODE (just delete the #)
    #HDP_NAME_NODE: 'hdfs://<HDP_MASTER_NODE>:8020'
    # ii) comment out the other line HDP_NAME_NODE: 'hdfs://fcicluster'
    #  Scoring Oozie workflow config
    # By default, yarn decides the HDP container requirements. But it can be overridden by providing the below attributes.
    # The values are indicative and will depend on HDP cluster resources.
    SCORING_DRIVER_MEMORY: '2048m'
    SCORING_EXECUTOR_MEMORY: '2048m'
    SCORING_NO_OF_EXECUTORS: '8'
    SCORING_NO_PARTITIONS: '8'

    # Time interval for running Entity Resolution (in seconds)
    RESOLUTION_TIME_INTERVAL: '1800'
    # Complete current Entity Resolution workflow jobs before starting
    # another one. Applies to interval processing only.
    RESOLUTION_COMPLETE_WORKFLOW: 'false'
    # Daily scheduled time for running Entity Resolution (HH:mm)
    #RESOLUTION_RUNTIME: '23:59'

    # Time interval for running the Watchlist matching process (in seconds)
    WATCHLIST_PROCESSING_INTERVAL: '300'
    # Daily scheduled time for running the Watchlist matching process (HH:mm)
    # WATCHLIST_PROCESSING_RUNTIME: '23:59'

    ## Party enrichment configuration
    # Entity Enrichment Endpoint(default=Entity Enrichment product exposed endpoint as specified below)
    ENRICHMENT_ENDPOINT: 'https://fci-ees-engine:443/v1/entities/auto-enrich'
    # Comma separated list of plans to be executed
    # A value of '' means party enrichment is not enabled
    ENRICHMENT_PLANS: ''
    # Party type of enrich (o=Organizations, i=Individuals, a=All  default=a)
    ENRICHMENT_PARTY_TYPE: 'a'
    # Party operation type to enrich (i=Insert, a=all (Insert and Update)  default=a)
    ENRICHMENT_OPERATION_TYPE: 'a'
    # Party process type using enrichment. A value of
    # i. 'false' allows only parties created via REST API to be enriched.
    # ii.'true' allows all parties(created via async - bulk load, or sync - REST API) to be enriched
    # default='true'
    ENRICHMENT_ALL_PARTIES: 'true'
    # Enrichment batch size and frequency
    ENRICHMENT_PUBLISH_BATCH_SIZE: '100'
    ENRICHMENT_PUBLISH_PERIOD_SECONDS: '300'


    # HBase REST Configuration
    # The value is required for
    # a) DERS
    # b) watchlist processing

    # fully qualified domain name of the Hadoop  (HDP) master node, for example HBASE_REST_SERVER: 'master.acme.com'
    HBASE_REST_SERVER: '<hostname>'
    HBASE_REST_PORT: '9081'
    HBASE_REST_SECURE_CONNECTION: 'true'

search:
  # set to False to disable Search
  # set to True otherwise
  enabled: True

  liberty:
    resources: {}
    image:
      repository: ibmcom/fci-search-liberty
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

common-ui:
  nodejs:
    image:
      repository: ibmcom/fci-common-ui
      tag: <BUILD_TAG>
  nginx:
    image:
      repository: ibmcom/fci-common-ui-web
      tag: <BUILD_TAG>
  investigativeUI:
    image:
      repository: ibmcom/fci-investigative-ui
      tag: <BUILD_TAG>

    # set to 0 to disable the Investigative UI
    # otherwise set to 1
    replicas: 1

  iuiStaticConfig:
    image:
      repository: ibmcom/fci-investigative-ui-config
      tag: <BUILD_TAG>


  iuiConfigService:
    image:
      repository: ibmcom/fci-investigative-ui-config-service
      tag: <BUILD_TAG>

  iuiNarrativeService:
  # set to False to disable Narrative Service
  # set to True otherwise
    enabled: False

    image:
      repository: ibmcom/fci-narrative-service
      tag: <BUILD_TAG>

  nginxConfig:
    # INCLUDE_CONFIG is a comma-separated list of components to include
    # valid values are: case,cedm,odm,search,fcai,fcdd,sifs,graph
    INCLUDE_CONFIG: 'case,cedm,odm,search,graph'


  bkPvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 1Gi

  nginxPvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 512Mi

  config:
    APP_ROLE_ANALYST: 'home'
    APP_ROLE_INVESTIGATOR: 'home'
    APP_ROLE_SUPERVISOR: 'home'
    APP_ROLE_ADMIN: 'home'
    APP_ROLE_DATA_SCIENTIST: 'home'
    APP_ROLE_EXECUTIVE: 'home'
    APP_ROLE_QUALITY_ASSURANCE: 'home'
    APP_ROLE_READ_ONLY: 'home'
    APP_ROLE_CONFIDENTIAL: 'home'

    # Set to 'true' if SSO is enabled.  The login form will then be replaced with a link to login through the SSO provider.
    SSO_ENABLED: 'false'
    # if using SAML without App ID then change to: security-auth/api/v1.0/login/saml
    SSO_PATH: "security-auth/api/v1.0/login/appid"

cdn-proxy:
  cdnProxy:
    image:
      repository: ibmcom/fci-cdn-proxy
      tag: <BUILD_TAG>

  bkPvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 5Gi

dsf:
  replicas: 0
  image:
    pullPolicy: IfNotPresent
    repository: ibmcom/kyc-data-source-framework
    tag: <BUILD_TAG>
  dsfConfig:
    DNB_USERNAME: ''
    POPULATE_DEFINITIONS_ON_STARTUP: 'true'
    DOWJONES_USERNAME: ''
    DOWJONES_NAMESPACE: ''
    KYCKR_USERNAME: ''
    TRANSUNION_TLO_USERNAME: ''
    TRANSUNION_EBUREAU_USERNAME: ''
    TRANSUNION_IDVISION_USERNAME: ''

ees-engine:
  replicas: 0
  image:
    pullPolicy: IfNotPresent
    repository: ibmcom/fci-shell-detection
    tag: <BUILD_TAG>

graph-writer:
  # set to False to disable Graph Liberty server
  # set to True otherwise
  enabled: True
  # runAsUser is the user id that containers requiring updates to file system permissions
  # run as if pvRequiresPermissionsFix is set to true
  runAsUser: 1000

  liberty:
    image:
      repository: ibmcom/fci-graph-writer
      tag: <BUILD_TAG>

  libertyInitPv:
    image:
      repository: ibmcom/fci-graph-writer-init-pv
      tag: <BUILD_TAG>

  kerberosClient:
    image:
      repository: ibmcom/fci-hdp-client
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

  gremlin:
    image:
      repository: ibmcom/fci-graph-gremlin-server
      tag: <BUILD_TAG>
    graphGremlinConfig:
      gremlinNodePort: "30184"


  libertyPvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 1Gi

  gremlinPvcSpec:
    accessModes:
      - ReadWriteMany
    storageClassName: null
    size: 1Gi
