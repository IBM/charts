# Passwords in this file are base64 encoded
# These passwords can be generated from the linux command line by using this command:
# echo -n "plaintext-password" | base64
# Note that the -n parameter to echo is important to avoid encoding a newline
# as part of the actual password.  Also keep the quotes (") around the password.
global:

  # Set to true if deploying on IBM Cloud Kubernetes Service (https://www.ibm.com/cloud/)
  # Set to false if deploying in FCI Softlayer Bare Metal Cloud and on premises.
  deployOnIBMCloud: false

  # Set to true if deploying on IBM Cloud Pak for Data
  deployOnCP4D: true

  # By default there will be one DB2 instance deployed.
  # Increase this number if additional DB2 instances need to be deployed.  Each component that uses DB2 will need to be configured with the correct DB2 instance if this value ir greater than 1.
  db2Instances: 1

  persistence:
    storageClassName: ''
    useDynamicProvisioning: true

  commonScripts:
    image:
      repository: ibmcom/fci-common-scripts
      tag: <BUILD_TAG>

  nginxSslProxy:
    image:
      repository: ibmcom/fci-nginx-ssl-proxy
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    resources:
      limits:
        cpu: 100m
        memory: 64Mi
      requests:
        cpu: 100m
        memory: 64Mi

  # If you want to monitor the resource utilization of your cluster and the nodes,
  # set this to true, else set this to false.

  enableMonitoring: true

  # SMTP Authentication to use for email alerting. Refer alertmanagerConfig and elastalertConfig further down this file
  smtp_auth_username: "<string>"
  smtp_auth_password: "<secret>"

  # The type of LDAP server being used.
  # Options include 'msad', 'sds', 'open', or 'none' (Keep the ' around the value)
  # msad -- Microsoft Active Directory
  # sds -- IBM Security Directory Server, formerly known as Tivoli Directory Server
  # open -- OpenLDAP
  # none -- no LDAP server, use basic registry instead
  # appid -- to enable authentication through IBM Cloud App ID service
  IDENTITY_SERVER_TYPE: 'msad'

  LDAP_SERVER_HOST: '<hostname>'
  LDAP_SERVER_PORT: '636'

  # set to True if connecting to the LDAP server over SSL
  # set to False otherwise
  LDAP_SERVER_SSL: True

  # The user account to connect (bind) to the LDAP server
  # For IBM Security Directory Server this is often 'cn=bind'
  LDAP_SERVER_BINDDN: 'administrator'

  # The LDAP_SERVER_SEARCHBASE is often referred to as the Base DN
  LDAP_SERVER_SEARCHBASE: 'cn=users,dc=aml,dc=ibm,dc=com'
  LDAP_PROFILE_DISPLAYNAME: 'displayName'
  LDAP_PROFILE_EMAIL: 'userPrincipalName'
  LDAP_PROFILE_GROUPS: 'memberOf'
  LDAP_PROFILE_ID: 'sAMAccountName'
  LDAP_SERVER_USERNAME_MAPPING: 'sAMAccountName'

  # These are the default user search filters:
  # for Microsoft Active Directory: objectcategory=user
  # for IBM Security Directory Server: objectclass=inetOrgPerson
  # for OpenLDAP: objectClass=inetOrgPerson
  # If using a custom LDAP user search filter, uncomment this property and enter the filter as the value.
  #LDAP_USER_FILTER_OVERRIDE: 'objectclass=ePerson'

  # Performs a nested group search.
  # Set to true only if the LDAP server does not support recursive server-side searches.
  LDAP_SERVER_RECURSIVE_SEARCH: 'false'
  
  #For Non Cloud-Pak deployments, set the userid for non-root containers to run
  runAsUser: 1000
  
  #Set the Additional Group ID settings that the containers should run as
  #This depends on the GID of the shared storage like NFS
  fsGroupConfig:
    supplementalGroups:
    - 0
  
  hbase:
    # For the hbase_zookeeper_quorum property, you must specify at least one zookeeper
    # server. For a 6 server hdp install (prod topology)  Zookeeper servers are: HDP Master Node.
    # HDP Gateway and HDP Secondary Master. For 3 server hdp install (dev topology) the Zookeeper servers are:
    # HDP Master and HDP Gateway. For single server hdp install the Zookeeper server is the HDP Hostname.
    hbase_zookeeper_quorum: '<ZOOKEEPER_SERVER_1,ZOOKEEPER_SERVER_2,ZOOKEEPER_SERVER_N>'
    hbase_zookeeper_property_clientPort: '2181'

#platform-secrets:

db2:
  hostIPC: true
  # Select antiAffinity as either hard or soft
  podAntiAffinity: hard

  resources:
    requests:
      memory: "5Gi"
      cpu: "0.5"
    limits:
      memory: "32Gi"
      cpu: "8"

  #Load Balancer Node Ports - Ports to expose in loadbalancer for CP4D installs
  # Set to an empty string to use a random port
  sslNodePort: "30560"

  image:
    repository: ibmcom/fci-data-store-server
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

global-name-mgmt:
  enabled: false

  image:
    repository: ibmcom/fci-global-name-mgmt
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

kafka:
  # Set to False to disable Kafka in a non-production environment
  enabled: True

  # A cluster of three Kafka and Zookeeper instances is created by default.
  # In a non-production environment, a cluster of one Kafka and Zookeeper instances can be used.
  replicas: 3
  zookeeperReplicaCount: 3

  # Max File Descriptors
  ulimitNofiles: '131072'

  image:
    repository: ibmcom/fci-kafka
    tag: "<BUILD_TAG>"
    pullPolicy: "IfNotPresent"

  ## Topic creation and configuration.
  ## The job will be run on a deployment only when the config has been changed.
  ## - If 'partitions' is specified we create the topic (with --if-not-exists.)
  ## - If 'partitions' is specified we 'alter' the number of partitions. This will
  ## silently and safely fail if the new setting isn't strictly larger than the old (i.e. a NOOP.) Do be aware of the
  ## implications for keyed topics (ref: https://docs.confluent.io/current/kafka/post-deployment.html#admin-operations)
  ## - If 'defaultConfig' is specified it's deleted from the topic configuration. If it isn't present,
  ## it will silently and safely fail.
  ## - If 'config' is specified it's added to the topic configuration.
  ##
  topics:
    - name: Party-General
      partitions: 1
    - name: Party-Match-Upload
      partitions: 1
    - name: Party-Resolved-Update
      partitions: 1
    - name: Party-Delete
      partitions: 1
    - name: FCI_IGA_AI_Data_Account
      partitions: 1
    - name: FCI_IGA_AI_Data_Transaction
      partitions: 1
    - name: FCDD_ML_CLASSIFIED
      partitions: 1
    - name: FCI_SEC_AuditRecords
      partitions: 1
    - name: sifs.email.in
      partitions: 10
    - name: sifs.chat.in
      partitions: 10
    - name: sifs.alert.in
      partitions: 1
    - name: sifs.ecomm.in
      partitions: 10
    - name: sifs.voice.in
      partitions: 1
    - name: sifs.attach.in
      partitions: 3

  ## Configuration Overrides. Specify any Kafka settings you would like set on the StatefulSet
  ## here in map format, as defined in the official docs.
  ## ref: https://kafka.apache.org/documentation/#brokerconfigs
  ## The end user does not need to edit any of these configurations
  configurationOverrides:
    "listener.security.protocol.map": "SSL:SSL,EXTERNAL:SSL"
    "inter.broker.listener.name": "SSL"
    "ssl.endpoint.identification.algorithm": ""

    # client authentication is requested, but a client without certs can still connect.
    # Change to "required" if client authentication is required.
    "ssl.client.auth": "requested"
    "confluent.support.metrics.enable": false
    "advertised.listeners": |-
     EXTERNAL://${MASTER_HOST}:${NODE_PORT}

  #First Listerner Port to hit the kafka externally.
  # Set to an empty string to use a random port
  nodeport:
    firstListenerPort: "31090"
  zookeeper:
    image:
      repository: ibmcom/fci-zookeeper
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    # The external port for Zookeeper.
    # Set to an empty string to use a random port
    externalNodePort: "32181"

mongodb:
  enabled: True
  securityContext:
    enabled: false
  # If the customer has permanently disabled IPv6
  # (including for all kernel updates)
  # change this value to false so that mongodb will start.
  mongodbEnableIPv6: true

  image:
    repository: "ibmcom/fci-mongodb"
    tag: "<BUILD_TAG>"
    pullPolicy: "IfNotPresent"

elasticsearch:
  enabled: True

  config:
    ES_ADMIN_DN: "CN=FCI_server,OU=FCI_platform,O=FCI_Development,C=US"
    # The number of minutes to wait until Elasticsearch starts.
    # If Elasticsearch has not started within this amount of time, then the Elasticsearch
    # container will be restarted.
    # Increase this value on systems with a slow disk.
    WAIT_MINUTES: '3'

  image:
    repository: ibmcom/fci-logsearch
    tag: "<BUILD_TAG>"
    pullPolicy: "IfNotPresent"

odm:
  # set to False to disable ODM
  # set to True otherwise
  enabled: False

  dbClient:
    image:
      repository: ibmcom/fci-rms-odm-data-store
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

  odm:
    image:
      repository: ibmcom/fci-rms-odm
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

  config:
    FLYWAY_BASELINE_VERSION: '01.01.01.00.005'

wca:
  enabled: false

  image:
    repository: ibmcom/fci-wca
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

cognos:
  enabled: false

  image:
    repository: ibmcom/fci-cognos
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

  resources:
    requests:
      memory: 10Gi

  proxy:
    resources: {}
    image:
      repository: ibmcom/fci-dashboards-proxy
      tag: <BUILD_TAG>
      pullPolicy: "IfNotPresent"

prometheus:

  alertmanager:
    image:
      repository: prom/alertmanager

  kubeStateMetrics:
    image:
      repository: quay.io/coreos/kube-state-metrics

  nodeExporter:
    image:
      repository: prom/node-exporter

  server:
    image:
      repository: prom/prometheus

  alertmanagerConfig:
    # How frequent do you want alerts for the same alert violation
    repeat_interval: 4h

    # Set this to true if you need email alerts specific to cluster resource utilization from alertmanager
    enable_smtp: false

    #Configure smtp if enable_smtp is set to true
    # NOTE: remove the authentication mechanisms you won't use
    smtp_config:
      # SMTP Server to use to send emails with port
      # example: mail.mycompany.com:587
      # The port could be 25, 587 or 465 depending on your SMTP Server
      smtp_smarthost: "<smtp_smarthost>"

      # The sender of the email alerts
      # example: noreply@mycompany.com
      smtp_from: "<noreply@mycompany.com>"

      # The authentication can happen in one of the three ways
      # Provide smtp_auth_username and smtp_auth_password in global section of this file to use SMTP Auth using LOGIN
      # The other two ways, PLAIN and CRAM-MD5 can be configured below for alertmanager

      ## SMTP Auth using PLAIN, Comment this out if you are using another mechanism. Uncomment below line to use this method
      #smtp_auth_identity: "<string>"

      ## SMTP Auth using CRAM-MD5, Comment this out if you are using another mechanism. Uncomment below line to use this method
      #smtp_auth_secret: "<secret>"

      #SMTP TLS Requirement. If set to true, add smtp_server.crt to secrets directory prior install
      smtp_require_tls: false

    # We use only "default receiver" to configure alertmanager.
    # email_configs is used if enable_smtp is set to true
    receiver_email: "<receiver@mycompany.com>"

    # Get notified once an alert is resolved
    send_resolved: true

    # Send in extra global configurations you want in the alertmanager.yml
    extra_global_config: {}

    # Send in additional receiver configs other than email optionally
    # Refer https://prometheus.io/docs/alerting/configuration/#receiver
    receiver_config: {}

grafana:
  image:
    repository: ibmcom/fci-grafana
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

  #Set the username to login to the grafana
  adminUser: "grafanauser"

crypto-utils:
  enabled: True
  image:
    repository: ibmcom/fci-crypto-utils
    tag: <BUILD_TAG>
    pullPolicy: "IfNotPresent"

  resources: {}

logging:
  # set to False to disable logging infrastructure in a non-production environment
  enabled: True

  filebeat:
    image:
      repository: ibmcom/fci-logshipper
      tag: <BUILD_TAG>

  logstash:
    image:
      repository: ibmcom/fci-loganalysis
      tag: <BUILD_TAG>

  kibana:
    image:
      repository: ibmcom/fci-logvisualization
      tag: <BUILD_TAG>

  logsearchCurator:
    image:
      repository: ibmcom/fci-logsearch-curator
      tag: <BUILD_TAG>

  #Set this to true if you want logs based alerting pointing to a logging stack outside FCI Platform
  #Refer documentation to configure rules
  elastalertOnly: False

  elastalertConfig:
    image:
      repository: ibmcom/fci-elastalert
      tag: <BUILD_TAG>
    # Default interval between alert checks against the elasticsearch datasource, in minutes
    runIntervalMins: 15
    # The index to which elastalert will write its alerts and statuses
    writebackIndex: elastalert
    # Default time before realerting, in minutes
    realertIntervalMins: 240

    # If configuring email alerts in rules, set email_alerts to true
    # Provide smtp_auth_username and smtp_auth_password in global section of this file to use SMTP Auth using LOGIN
    # Credentials provided in the global section is mounted on to /opt/elastalert/smtp_auth.yml
    # SMTP Configuration can be directly provided in the rules configured. Refer to documentation.
    emailAlerts: false

    #SMTP TLS Requirement. If set to true, add smtp_server.crt to secrets directory prior install
    smtp_ssl: false

    elasticsearch:
      # elasticsearch endpoint
      host: elasticsearch
      # elasticsearch port
      port: 9200

security-audit:
  # set to False to disable auditing in a non-production environment
  enabled: True

  image:
    repository: ibmcom/fci-security-audit-app
    tag: <BUILD_TAG>
    pullPolicy: IfNotPresent

  config:
    FLYWAY_BASELINE_VERSION: '2019.02.28.13.59.00'

  db2:
    image:
      repository: ibmcom/fci-security-audit-data-store
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

security-auth:
  replicas: 2
  nodejs:
    resources: {}
    image:
      repository: ibmcom/fci-security-auth
      tag: '<BUILD_TAG>'
      pullPolicy: IfNotPresent
  redis:
    resources: {}
    image:
      repository: ibmcom/fci-memoryds
      tag: '<BUILD_TAG>'
      pullPolicy: IfNotPresent


  securityAuthConfig:
    # set to '0' to disable auditing in a non-production environment
    AUDIT_ACTIVE: '1'

    # Role definitions
    # Do not modify  the Role definitions below
    ROLE_ANALYST: 'analyst'
    ROLE_INVESTIGATOR: 'investigator'
    ROLE_SUPERVISOR: 'supervisor'
    ROLE_ADMIN: 'admin'
    ROLE_DATA_SCIENTIST: 'data_scientist'
    ROLE_EXECUTIVE: 'executive'
    ROLE_QUALITY_ASSURANCE: 'quality_assurance'
    ROLE_READ_ONLY: 'read_only'
    ROLE_CONFIDENTIAL: 'confidential'

    # UI configuration definitions
    # Do not modify the UI configurations below
    ROLE_SURVEILLANCE: 'si'
    ROLE_COMPLAINTS: 'si-complaints'
    ROLE_CASE_MANAGER: 'case_manager'
    ROLE_INSURANCE: 'insurance'
    ROLE_KYC: 'kyc'
    ROLE_FTR: 'si-ftr'
    ROLE_GRAPH: 'graph'
    ROLE_ALERTS_INSIGHT: 'alerts_insight'
    ROLE_TOOLING: 'tooling'
    ROLE_TLS: 'tls'

    # Team definitions
    # NOTE: The team names must begin with TEAM_
    # These values can be changed but you must follow documentation
    # under the section called Changing Team Names (do a search for it in the
    # documentation). It is under topic Managing groups, roles, UI configurations, and teams
    TEAM_TRIAGE_TEAM: 'TriageTeam'
    TEAM_INVESTIGATION_TEAM: 'InvestigationTeam'
    TEAM_SUPERVISOR_TEAM: 'SupervisorTeam'
    TEAM_CONFIDENTIAL_TEAM: 'confidential'
    TEAM_VENDOR_TEAM: 'VendorTeam'
    TEAM_LEGAL_TEAM: 'LegalTeam'

    # Role groups
    GROUP_ANALYST: 'CN=analysts,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_INVESTIGATOR: 'CN=investigators,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_SUPERVISOR: 'CN=supervisors,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_ADMIN: 'CN=admins,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_DATA_SCIENTIST: 'CN=datascientists,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_EXECUTIVE: 'CN=executives,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_QUALITY_ASSURANCE: 'CN=qualityassurance,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_READ_ONLY: 'CN=readonly,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_CONFIDENTIAL: 'CN=confidential,CN=Users,DC=aml,DC=ibm,DC=com'

    # UI configuration groups
    GROUP_SURVEILLANCE: 'CN=surveillance,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_COMPLAINTS: 'CN=complaints,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_CASE_MANAGER: 'CN=casemanager,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_INSURANCE: 'CN=insurance,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_KYC: 'CN=kyc,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_FTR: 'CN=ftr,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_GRAPH: 'CN=graph,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_ALERTS_INSIGHT: 'CN=alerts_insight,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_TOOLING: 'CN=tooling,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_TLS: 'CN=tls,CN=Users,DC=aml,DC=ibm,DC=com'

    # Team groups
    GROUP_TRIAGE_TEAM: 'CN=TriageTeam,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_INVESTIGATION_TEAM: 'CN=InvestigationTeam,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_SUPERVISOR_TEAM: 'CN=SupervisorTeam,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_CONFIDENTIAL_TEAM: 'CN=confidential,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_VENDOR_TEAM: 'CN=VendorTeam,CN=Users,DC=aml,DC=ibm,DC=com'
    GROUP_LEGAL_TEAM: 'CN=LegalTeam,CN=Users,DC=aml,DC=ibm,DC=com'



    # specify internal user registry (also known as basic registry)
    # for each numbered user, specify the user's id, roles, and password
    # roles are comma separated
    # valid roles include: admin, analyst, investigator, supervisor, data_scientist
    # password are specified in the secrets.yaml file of the install toolkit
    # to add additional users, add additional user properties numbered 17, 18, etc.
    USER_ID_1: fciadmin
    USER_ROLES_1: admin
    USER_TEAMS_1: SupervisorTeam
    USER_ID_2: fcianalyst
    USER_ROLES_2: analyst
    USER_TEAMS_2: TriageTeam
    USER_ID_3: fciinvestigator
    USER_ROLES_3: investigator
    USER_TEAMS_3: InvestigationTeam
    USER_ID_4: fcisupervisor
    USER_ROLES_4: supervisor
    USER_TEAMS_4: SupervisorTeam
    USER_ID_5: fcidatascientist
    USER_ROLES_5: data_scientist
    USER_TEAMS_5: InvestigationTeam
    USER_ID_6: fciconfidential
    USER_ROLES_6: confidential
    USER_TEAMS_6: confidential
    USER_ID_7: fciiadmin
    USER_ROLES_7: admin,insurance
    USER_TEAMS_7: SupervisorTeam,InsuranceTeam
    USER_ID_8: fciianalyst
    USER_ROLES_8: analyst,insurance
    USER_TEAMS_8: TriageTeam,InsuranceTeam
    USER_ID_9: fciiinvestigator
    USER_ROLES_9: investigator,insurance
    USER_TEAMS_9: InvestigationTeam,InsuranceTeam
    USER_ID_10: fciisupervisor
    USER_ROLES_10: supervisor,insurance
    USER_TEAMS_10: SupervisorTeam,InsuranceTeam
    USER_ID_11: tlsadmin
    USER_ROLES_11: admin,tls
    USER_TEAMS_11: SupervisorTeam
    USER_ID_12: fcaisupervisor
    USER_ROLES_12: alerts_insight,supervisor
    USER_TEAMS_12: TriageTeam
    USER_ID_13: fcaianalyst
    USER_ROLES_13: alerts_insight,analyst
    USER_TEAMS_13: TriageTeam
    USER_ID_14: fcaiinvestigator
    USER_ROLES_14: alerts_insight,investigator
    USER_TEAMS_14: TriageTeam
    USER_ID_15: fcaiadmin
    USER_ROLES_15: alerts_insight,admin
    USER_TEAMS_15: TriageTeam
    USER_ID_16: toolingadmin
    USER_ROLES_16: admin,data_scientist
    USER_TEAMS_16: SupervisorTeam

    # JWT_KEY_EXPIRY is the length of time before the security token expires
    # This controls the length of a user's session after logging in.
    # The value is expressed in a time span. e.g.:  "30m", "4h", "1d"
    JWT_KEY_EXPIRY: '4h'
    # DO NOT CHANGE THIS VALUE:
    JWT_ISSUER: 'fci.ibm.com'

    #SAML configuration
    SAML_DISABLEREQUESTEDAUTHNCONTEXT: "true"
    # identity provider entrypoint
    # This is typically the URL provided by the identity provider for a user to log in
    SAML_ENTRY_POINT: 'https://<hostname>/adfs/ls'
    # name identifier format to request from identity provider
    SAML_IDENTIFIERFORMAT: 'urn:oasis:names:tc:SAML:1.1:nameid-format:unspecified'
    # issuer string to supply to identity provider
    SAML_ISSUER: 'https://<hostname>/adfs/services/trust'
    # the SAML profile property that maps to a user's display name
    SAML_PROFILE_DISPLAYNAMEPROP: 'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name'
    # the SAML profile property that maps to a user's email address
    SAML_PROFILE_EMAILPROP: 'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress'
    # the SAML profile property that maps to a user's groups
    SAML_PROFILE_GROUPSPROP: 'http://schemas.xmlsoap.org/claims/Group'
    # the SAML profile property that maps to a user's id
    SAML_PROFILE_NAMEIDPROP: 'nameID'
    # SAML_ACCEPTED_CLOCK_SKEW is the time in milliseconds of skew
    # that is acceptable between client and server
    # when checking OnBefore and NotOnOrAfter assertion condition validity timestamps.
    # Setting to -1 will disable checking these conditions entirely.
    SAML_ACCEPTED_CLOCK_SKEW: '5000'

    ### IBM Cloud AppID configuration ###
    ## You can find these configuration values by clicking View credentials
    ## in the 'Service credentials' tab of your AppID service's manage section.
    # The client ID for the App ID instance of service.
    APPID_CLIENT_ID: <clientId>
    # Tenant ID is specific to our App ID instance
    APPID_TENANTID: <tenantId>
    # The App ID oauth server URL which is used for redirecting user to IBM Cloud app ID based authentication.
    APPID_OAUTH_SERVER_URL: "https://appid-oauth.ng.bluemix.net/oauth/v3/<tenantId>"
    # The App ID profiles URL.
    APPID_PROFILES_URL: "https://appid-profiles.ng.bluemix.net"
    # The App ID API version.
    APPID_VERSION: "3"
    # End Point for the app ID service.
    APPID_SERVICE_ENDPOINT: "https://us-south.appid.cloud.ibm.com"
    # Default Call back URL needed for redirecting to security-auth service after AppID authentication.
    APPID_CALLBACK_URL: "/security-auth/ibm/bluemix/appid/callback"
    # Default Call back URL needed for redirecting to security-auth service after AppID authentication.
    APPID_IAM_TOKEN_URL: "https://iam.cloud.ibm.com/identity/token"

    # BRUTE_THROTTLING is set to 'true' to enable throttling of requests from an IP address
    # when too many invalid logins have occurred from that IP address.
    # It is used to prevent brute force attacks.
    # Set to 'false' to disable this feature.
    BRUTE_THROTTLING: 'true'
    # BRUTE_FREE_RETRIES specifies the number of invalid logins before throttling begins
    BRUTE_FREE_RETRIES: '5'

case-manager:
  # set to False to disable Case Manager
  # set to True otherwise
  enabled: True

  mq:
    #Load Balancer Node Ports - Port to expose in loadbalancer for CP4D installs
    # Set to an empty string to use a random port
    mqNodePort: "30683"
    image:
      repository: ibmcom/fci-messaging
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    resources:
      requests:
        memory: "256Mi"
        cpu: ".1"
      limits:
        memory: "512Mi"
        cpu: "2"
    nodeSelector: {}
    tolerations: []
    affinity: {}
  liberty:
    image:
      repository: ibmcom/fci-solution
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent
    resources:
      requests:
        memory: "256Mi"
        cpu: ".1"
      limits:
        memory: "9Gi"
        cpu: "4"
    nodeSelector: {}
    tolerations: []
    affinity: {}
  libertyConfig:
    env_fci_batch_userid: 'fcibatch'

cedm:
  # set to False to disable CEDM
  # set to True otherwise
  enabled: True

  liberty:
    image:
      repository: ibmcom/fci-cedm-integration
      tag: <BUILD_TAG>
    resources:
      requests:
        memory: "256Mi"
        cpu: "0.03"
      limits:
        memory: "4Gi"
        cpu: "1"
  db2:
    image:
      repository: ibmcom/fci-cedm-data-store-client
      tag: <BUILD_TAG>

  cedmConfig:
    FLYWAY_BASELINE_VERSION: '01.01.01.00.119'

    # Publish batch size and frequency
    PARTY_PUBLISH_BATCH_SIZE: '250'
    PARTY_PUBLISH_PERIOD_SECONDS: '300'

    # Big Match Oozie Workflow Config
    OOZIE_MAX_JVM_HEAP_SIZE: '4712'

    OOZIE_NUM_OF_WORKER_TASKS: '4'
    # If using the HDP development environment, set the number of worker tasks to 2
    # If using a single HDP server, set the number of worker tasks to 1.
    #OOZIE_NUM_OF_WORKER_TASKS: '2'

    OOZIE_NUM_OF_THREADS_FOR_EACH_WORKER: '1'
    OOZIE_PORT: '11000'
    OOZIE_JOBTRACKER_PORT: '8050'
    OOZIE_SECURE_CONNECTION: 'false'
    # The Fully Qualified DNS Name (FQDN) of the Oozie server.  The Oozie server is the
    # Hadoop Master for both production topology (6 servers), dev topology (3 servers) and
    # single HDP server install.
    OOZIE_SERVER: '<hostname>'
    OOZIE_USER_NAME: 'bigmatch'

    # If using the HDP development environment or HDP single server do two things to configure the HDP_NAME_NODE
    # i) uncomment the the line below and provide HDP_MASTER_NODE (just delete the #)
    #HDP_NAME_NODE: 'hdfs://<HDP_MASTER_NODE>:8020'
    # ii) comment out the other line HDP_NAME_NODE: 'hdfs://fcicluster'

    # If using the HDP production environment, leave the line below as is. For HDP dev env. & single server comment it out
    HDP_NAME_NODE: 'hdfs://fcicluster'

    # Scoring Oozie workflow config
    SCORING_DRIVER_MEMORY: '5500m'
    SCORING_EXECUTOR_MEMORY: '2600m'
    SCORING_NO_OF_EXECUTORS: '8'
    SCORING_NO_PARTITIONS: '8'

    # Time interval for running Entity Resolution (in seconds)
    RESOLUTION_TIME_INTERVAL: '1800'
    # Complete current Entity Resolution workflow jobs before starting
    # another one. Applies to interval processing only.
    RESOLUTION_COMPLETE_WORKFLOW: 'false'
    # Daily scheduled time for running Entity Resolution (HH:mm)
    #RESOLUTION_RUNTIME: '23:59'

    # Party enrichment configuration
    # ENRICHMENT_ENDPOINT: 'https:<fully_qualified_host_name:port>'
    # Comma separated list of plans to be executed
    # ENRICHMENT_PLANS:
    # Party type of enrich (o=Organizations, i=Individuals, a=All  default=o)
    # ENRICHMENT_PARTY_TYPE:
    # Party operation type to enrich (i=Insert, a=all (Insert and Update)  default=i)
    # ENRICHMENT_OPERATION_TYPE:
    # ENRICHMENT_CLIENT_ID:
    # ENRICHMENT_CLIENT_SECRET:

    # HBase REST Configuration
    # HBASE_REST_SERVER: '<hostname>'
    # HBASE_REST_PORT: '9081'
    # HBASE_REST_SECURE_CONNECTION: 'true'

search:
  # set to False to disable Search
  # set to True otherwise
  enabled: True

  liberty:
    resources: {}
    image:
      repository: ibmcom/fci-search-liberty
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

rms:
  # set to False to disable RMS
  # set to True otherwise
  enabled: False

  db2Client:
    image:
      repository: ibmcom/fci-rms-data-store
      tag: <BUILD_TAG>
      pullPolicy: IfNotPresent

  rmsDesignStudio:
    image:
      repository: ibmcom/fci-rms-designstudio
      tag: <BUILD_TAG>

  rmsStreamsVoice:
    image:
      repository: ibmcom/rms-streams-voice
      tag: <BUILD_TAG>

  rmsConfig:
    FLYWAY_BASELINE_VERSION: '01.01.01.00.020'
    #<hdp_host> is the active name node.
    JUPYTER_URL: "https://<hdp_host>:5033/analytics/models/v1/jupyter/"
    JOB_URL: "https://<hdp_host>:5006/job"
    DISCOVERY_URL: "https://<hdp_host>:5004/discovery"
    NLU_URL: "https://<hdp_host>:5007/nlu"
    NLC_URL: "https://<hdp_host>:5001/nlc"
    LIVY_URL: "https://<hdp_host>:8998/batches"
    HDFS_URL: "hdfs://localhost/"
    CANCEL_PIPELINE_JOB_URL: "https://<hdp_host>:5013/cancel"
    HDFS_ACCESS_URL: "hdfs://<hdp_host>:50070"

  config:
    #Enter HDP MASTER IP and PASSWORD
    HDP_MASTER_IP: '9.9.9.9'

common-ui:
  nodejs:
    image:
      repository: ibmcom/fci-common-ui
      tag: <BUILD_TAG>
  nginx:
    image:
      repository: ibmcom/fci-common-ui-web
      tag: <BUILD_TAG>
  investigativeUI:
    image:
      repository: ibmcom/fci-investigative-ui
      tag: <BUILD_TAG>

    # set to 0 to disable the Investigative UI
    # otherwise set to 1
    replicas: 1

  iuiStaticConfig:
    image:
      repository: ibmcom/fci-investigative-ui-config
      tag: <BUILD_TAG>


  iuiConfigService:
    image:
      repository: ibmcom/fci-investigative-ui-config-service
      tag: <BUILD_TAG>

  nginxConfig:
    # INCLUDE_CONFIG is a comma-separated list of components to include
    # valid values are: case,cedm,odm,search,rms,fcai,fcdd,sifs,graph
    INCLUDE_CONFIG: 'case,cedm,odm,search,rms,graph'

  config:
    APP_ROLE_ANALYST: 'home'
    APP_ROLE_INVESTIGATOR: 'home'
    APP_ROLE_SUPERVISOR: 'home'
    APP_ROLE_ADMIN: 'home'
    APP_ROLE_DATA_SCIENTIST: 'home'
    APP_ROLE_EXECUTIVE: 'home'
    APP_ROLE_QUALITY_ASSURANCE: 'home'
    APP_ROLE_READ_ONLY: 'home'
    APP_ROLE_CONFIDENTIAL: 'home'

    # Set to 'true' if SSO is enabled.  The login form will then be replaced with a link to login through the SSO provider.
    SSO_ENABLED: 'false'
    # if using SAML without App ID then change to: security-auth/api/v1.0/login/saml
    SSO_PATH: "security-auth/api/v1.0/login/appid"

cdn-proxy:
  cdnProxy:
    image:
      repository: ibmcom/fci-cdn-proxy
      tag: <BUILD_TAG>

minio:
  minio:
    image:
      repository: ibmcom/fci-docker-minio
      tag: <BUILD_TAG>

graph-writer:
  # set to False to disable Graph Liberty server
  # set to True otherwise
  enabled: True

  liberty:
    image:
      repository: ibmcom/fci-graph-writer
      tag: <BUILD_TAG>

  libertyInitPv:
    image:
      repository: ibmcom/fci-graph-writer-init-pv
      tag: <BUILD_TAG>

  gremlin:
    image:
      repository: ibmcom/fci-graph-gremlin-server
      tag: <BUILD_TAG>


  graphGremlinConfig:
    GRAPH_WRITER_ZOOKEEPER_ZNODE: /hbase-unsecure
    GRAPH_WRITER_ELASTICSEARCH_HOSTNAME_VERIFICATION_DISABLE: 'true'
