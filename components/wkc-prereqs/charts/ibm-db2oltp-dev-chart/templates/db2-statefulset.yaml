{{- include "sch.config.init" (list . "db2oltp.sch.chart.config.values") -}}
apiVersion: v1
kind: Service
metadata:
  name: {{ template "fullname" . }}
  labels:
    app: {{ template "fullname" . }}
    chart: "{{ .Chart.Name }}"
    component: "db2"
    release: "{{ .Release.Name }}"
    heritage: "{{ .Release.Service }}"
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
    app.kubernetes.io/name: {{ .Chart.Name }}
    helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version | replace "+" "_" }}
spec:
  ports:
  - port: 50000
    name: main
    targetPort: 50000
    protocol: TCP
  - port: 55000
    name: text
    targetPort: 55000
    protocol: TCP
  - port: 60006
    name: db2hadrp
    targetPort: 60006
    protocol: TCP
  - port: 60007
    name: db2hadrs
    targetPort: 60007
    protocol: TCP
{{- if .Values.service.ssl }}
  - port: 50001
    name: ssl
    targetPort: 50001
    protocol: TCP
{{- end }}
  clusterIP: None
  selector:
    app: {{ template "fullname" . }}
    component: "db2"
---

{{- if semverCompare ">=1.11.1" .Capabilities.KubeVersion.GitVersion }}
apiVersion: apps/v1
{{- else if .Capabilities.APIVersions.Has "apps/v1beta2" }}
apiVersion: apps/v1beta2
{{- else }}
apiVersion: apps/v1beta1
{{- end }}
kind: StatefulSet
metadata:
  name: {{ template "fullname" . }}
  labels:
    app: {{ template "fullname" . }}
    chart: "{{ .Chart.Name }}"
    component: "db2"
    release: "{{ .Release.Name }}"
    heritage: "{{ .Release.Service }}"
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
    app.kubernetes.io/name: {{ .Chart.Name }}
    helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version | replace "+" "_" }}
spec:
  selector:
    matchLabels:
      app: {{ template "fullname" . }}
      release: {{ .Release.Name }}
      heritage: {{ .Release.Service }}
      component: "db2"
  serviceName: {{ template "fullname" . }}
{{- if .Values.hadr.enabled }}
  podManagementPolicy: "Parallel"
  replicas: 2
{{- else }}
  replicas: 1
{{- end }}
  {{- if and (.Capabilities.KubeVersion.Major | hasPrefix "1") (.Capabilities.KubeVersion.Minor | hasPrefix "7") }}
  # Set updateStrategy to "RollingUpdate", if we're on Kubernetes 1.7.
  # It's already the default for apps/v1beta2 (Kubernetes 1.8 onwards)
  updateStrategy:
    type: OnDelete
  {{- end }}
  template:
    metadata:
      name: {{ template "fullname" . }}
      labels:
        app: {{ template "fullname" . }}
        chart: "{{ .Chart.Name }}"
        component: "db2"
        release: "{{ .Release.Name }}"
        heritage: "{{ .Release.Service }}"
        app.kubernetes.io/instance: {{ .Release.Name }}
        app.kubernetes.io/managed-by: {{ .Release.Service }}
        app.kubernetes.io/name: {{ .Chart.Name }}
        helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version | replace "+" "_" }}
        icpdsupport/app: "apis"
        {{ .Values.global.serviceabilityLabelName }}: {{ .Values.global.serviceabilityLabelValue }}
      annotations:
        {{- if .Values.global.podAnnotations }}
{{ toYaml .Values.global.podAnnotations | trim | indent 8 }}
        {{- end }}
    spec:
      hostNetwork: false
      hostPID: false
      affinity:
        nodeAffinity:
          #If you specify multiple nodeSelectorTerms associated with nodeAffinity types,
          #then the pod can be scheduled onto a node if one of the nodeSelectorTerms is satisfied.
          #
          #If you specify multiple matchExpressions associated with nodeSelectorTerms,
          #then the pod can be scheduled onto a node only if all matchExpressions can be satisfied.
          #
          #valid operators: In, NotIn, Exists, DoesNotExist, Gt, Lt
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            preference:
              matchExpressions:
              - key: wkc-privileged
                operator: In
                values:
                - {{ .Values.nodeLabel }}
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - {{ .Values.archx86_64 }}
                - {{ .Values.archppc64le }}
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app: "{{ template "fullname" . }}"
                  release: "{{ .Release.Name }}"
                  component: "db2"
            # avoid scheduling on same node as DB2U service instance. They use label "engine"     
            - topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  type: "engine"
            # prevent xmeta and wdp-db2 to schedule on same node.      
            - topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app: iis-xmetarepo
      volumes:
      - name: {{ template "datastorname" . }}
      {{- if and (.Values.persistence.enabled) (not .Values.hadr.enabled) }}
        persistentVolumeClaim:
        {{- if .Values.dataVolume.existingClaimName }}
          claimName: {{ .Values.dataVolume.existingClaimName }}
        {{- else }}
          claimName: {{ template "datastorname" . }}
        {{- end }}
      {{- else }}
        emptyDir: {}
      {{- end }}
      - name: {{ template "hadrstorname" . }}
      {{- if and (.Values.persistence.enabled) (.Values.hadr.enabled) }}
        persistentVolumeClaim:
        {{- if .Values.hadrVolume.existingClaimName }}
          claimName: {{ .Values.hadrVolume.existingClaimName }}
        {{- else }}
          claimName: {{ template "hadrstorname" . }}
        {{- end }}
      {{- else }}
        emptyDir: {}
      {{- end }}
{{- if .Values.setSysctlsUsingJob }}
      - name: wdp-db2-sysctl-config
        configMap:
          name: wdp-db2-sysctl-config
          defaultMode: 0555
{{- end }}
      - name: cgvol
        hostPath:
          path: /sys/fs/cgroup
      - name: sys
        hostPath:
          path: /proc/sys
      - name: proc
        hostPath:
          path: /proc
      - emptyDir:
          medium: Memory
        name: dshm
      {{- if .Values.service.ssl }}
      - name: cert
        secret:
          defaultMode: 420
          secretName: {{ template "fullname" . }}-cert
      {{- end }}
      hostIPC: true
{{- if .Values.serviceAccount.name }}
      serviceAccountName: {{ .Values.serviceAccount.name }}
{{- end }}
      initContainers:
{{- if .Values.setKernelParamsInitContainer }}      
        - name: init-db2
          image: {{ if .Values.global.dockerRegistryPrefix }}{{ trimSuffix "/" .Values.global.dockerRegistryPrefix }}/{{ end }}{{ .Values.image.repository }}:{{ .Values.image.tag }}
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          securityContext:
            privileged: false
            readOnlyRootFilesystem: false
            allowPrivilegeEscalation: false
            {{- if .Values.directiveChanges.securityContext.runAsUser }}
            runAsUser: {{ .Values.directiveChanges.securityContext.runAsUser }}
            {{- end}}
          command: ['sh','-c','/var/db2_setup/lib/set_kernel_params.sh']
          resources:
{{ toYaml .Values.initContainer.resources | indent 13 }}
          volumeMounts:
          - name: proc
            mountPath: /host/proc
            readOnly:  false
          - name: sys
            mountPath: /host/proc/sys
            readOnly: false
{{- end }}            
{{- if .Values.setSysctlsUsingJob }}
        - name: init-sysctls
          image: {{ if .Values.global.dockerRegistryPrefix }}{{ trimSuffix "/" .Values.global.dockerRegistryPrefix }}/{{ end }}{{ .Values.initContainer.initImage.repository}}:{{ .Values.initContainer.initImage.tag }}
          imagePullPolicy: {{ .Values.initContainer.initImage.pullPolicy }}
          command: ["/bin/sh", "/job/runJob.sh"]
          resources:
{{ toYaml .Values.initContainer.resources | indent 13 }}
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          volumeMounts:
          - name: wdp-db2-sysctl-config
            mountPath: /job
{{- end }}
{{- if or .Values.initContainer.chown .Values.global.chownPV }}
        - name: init-chown-pv
          image: {{ if .Values.global.dockerRegistryPrefix }}{{ trimSuffix "/" .Values.global.dockerRegistryPrefix }}/{{ end }}{{ .Values.initContainer.initImage.repository}}:{{ .Values.initContainer.initImage.tag }}
          imagePullPolicy: {{ .Values.initContainer.initImage.pullPolicy }}
          command: ['sh']
          args:
          - "-c"
          - |
            set -ex;
{{- if .Values.securityContext.runAsUser }}
            sudo chown {{ .Values.securityContext.runAsUser }}:{{ .Values.securityContext.runAsUser }} /database;
            sudo chmod 755 /database;
{{- end }}
          securityContext:
            capabilities:
              add:
              - SETUID
              - SETGID
          {{- if .Values.initContainer.securityContext.runAsUser }}
            runAsUser: {{ .Values.initContainer.securityContext.runAsUser }}
          {{- end }}
          resources:
{{ toYaml .Values.initContainer.resources | indent 13 }}
          volumeMounts:
          - mountPath: /database
          {{- if .Values.hadr.enabled }}
            name: {{ .Values.dataVolume.name | quote }}
          {{- else }}
            name: {{ template "datastorname" . }}
          {{- end }}
{{- end }}
      containers:
      - name: {{ template "fullname" . }}
        image: {{ if .Values.global.dockerRegistryPrefix }}{{ trimSuffix "/" .Values.global.dockerRegistryPrefix }}/{{ end }}{{ .Values.image.repository }}:{{ .Values.image.tag }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        securityContext:
          capabilities:
            add: ["SYS_RESOURCE", "IPC_OWNER", "SYS_NICE"]
          {{- if .Values.directiveChanges.securityContext.runAsUser }}
          runAsUser: {{ .Values.directiveChanges.securityContext.runAsUser }}
          {{- end}}
        ports:
        - containerPort: 50000
        - containerPort: 55000
        {{- if .Values.service.ssl }}
        - containerPort: 50001
        {{- end }}
        env:
        - name: LICENSE
          value: "accept"
        - name: DB2INSTANCE
          value: {{ default "db2inst1" .Values.db2inst.instname | quote }}
        - name: DB2INST1_PASSWORD
          valueFrom:
            secretKeyRef:
              name: {{ template "fullname" . }}
              key: password
      {{- if not .Values.hadr.enabled }}
        - name: DBNAME
          value: "{{ .Values.options.databaseName }}"
        - name: CREATEDBCMD
          value: {{ .Values.options.createDBCmd | quote }}
      {{- else }}
        - name: DBNAME
          value: {{ default "sample" .Values.options.databaseName| quote }}
        - name: CREATEDBCMD
          value: {{ .Values.options.createDBCmd | quote }}
      {{- end }}
        - name: BLU
          value: "false"
        - name: ENABLE_ORACLE_COMPATIBILITY
          value: "{{ .Values.options.oracleCompatibility }}"
        - name: UPDATEAVAIL
          value: "NO"
        - name: ETCD_ENDPOINT
          value: "http://{{ template "fullname" . }}-etcd-0.{{ template "fullname" . }}-etcd:2379,http://{{ template "fullname" . }}-etcd-1.{{ template "fullname" . }}-etcd:2379,http://{{ template "fullname" . }}-etcd-2.{{ template "fullname" . }}-etcd:2379"
        - name: TO_CREATE_SAMPLEDB
          value: "false"
        - name: IS_OSXFS
          value: "false"
        - name: REPODB
          value: "false"
        - name: HADR_ENABLED
          value: "{{ .Values.hadr.enabled }}"
        - name: IS_KUBE
          value: "true"
        - name: SUPPORT_4K_DEVICE
          value: "{{ default false .Values.support4kDevice }}"
         #set liveness probe to determine if container needs to be restarted
         #- command, http, or tcp
         #ref : https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - su - $DB2INSTANCE  -c '/database/config/$DB2INSTANCE/sqllib/bin/db2gcf -s'
        {{- if not .Values.hadr.enabled }}
          initialDelaySeconds: 810
        {{- else }}
          initialDelaySeconds: 1620
        {{- end }}
          periodSeconds: 90
          failureThreshold: 3
          timeoutSeconds: 10
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              #!/bin/bash
              function errorExit () {
                echo "$1" 1>&2
                exit 1
              }

              su - ${DB2INSTANCE?} -c '/database/config/$DB2INSTANCE/sqllib/bin/db2gcf -s' || errorExit "db2instance is not active"

              dbs=$(su - ${DB2INSTANCE?} -c 'db2  LIST ACTIVE DATABASES')

              echo $dbs | grep "ILGDB" || errorExit "ILGDB DB is not active"
              echo $dbs | grep "LINEAGE" || errorExit "Lineage DB is not active"
              echo $dbs | grep "BGDB" || errorExit "Glossary DB is not active"
              echo $dbs | grep "WFDB" || errorExit "Workflow DB is not active"
        {{- if not .Values.hadr.enabled }}
          initialDelaySeconds: 60
        {{- else }}
          initialDelaySeconds: 360
        {{- end }}
          periodSeconds: 60
          failureThreshold: 30
          timeoutSeconds: 60
        resources:
{{ toYaml .Values.resources | indent 10 }}
        volumeMounts:
        - mountPath: /sys/fs/cgroup
          name: cgvol
          readOnly: true
        - mountPath: /database
        {{- if .Values.hadr.enabled }}
          name: {{ .Values.dataVolume.name | quote }}
        {{- else }}
          name: {{ template "datastorname" . }}
        {{- end }}
        - mountPath: /hadr
          name: {{ template "hadrstorname" . }}
        {{- if .Values.service.ssl }}
        - name: cert
          mountPath: /db2ssl
        {{- end }}
        - mountPath: /dev/shm
          name: dshm
{{- if .Values.global.image.secretName }}
      imagePullSecrets:
          - name: {{ .Values.global.image.secretName }}
{{- end }}
      securityContext:
      {{- if .Values.securityContext.runAsUser }}
        runAsUser: {{ .Values.securityContext.runAsUser }}
      {{- end }}
  volumeClaimTemplates:
  {{- if and (.Values.persistence.enabled) (not .Values.dataVolume.existingClaimName) }}
  - metadata:
      name: {{ template "datastorname" . }}
      labels:
        app: {{ template "fullname" . }}
        chart: "{{ .Chart.Name }}"
        component: "db2"
        release: "{{ .Release.Name }}"
        heritage: "{{ .Release.Service }}"
    spec:
      {{- if and .Values.global.persistence.useDynamicProvisioning (not .Values.dataVolume.overrideStorageClass) }}
      # If present, use the storageClassName from the values.yaml, else use the
      # default storageClass setup by Kubernetes Administrator
      #
      # Setting storageClassName to nil means use the default storage class
      storageClassName: {{ default nil .Values.global.persistence.storageClassName | quote }}
      {{- else }}
      storageClassName: {{ default "" .Values.dataVolume.storageClassName | quote }}
      {{- end }}
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: {{ .Values.dataVolume.size | quote }}
  {{- end }}
