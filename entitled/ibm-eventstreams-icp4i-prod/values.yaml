###############################################################################
#
# Licensed Materials - Property of IBM
#
# 5737-H33
#
# (C) Copyright IBM Corp. 2018, 2019  All Rights Reserved.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
###############################################################################
###############################################################################
############################# IBM EVENT STREAMS ###############################
###############################################################################


###############################################################################
# Values that are needed for all Event Streams charts and sub-charts
###############################################################################
global:
  # Whether the application is running production workloads
  production: false

  # Whether the application is running as a supporting program
  supportingProgram: false

  # Whether Event Streams should generate a certificate
  generateCertificate: false

  # The name of the certificate stored in a secret in the namespace
  # If global.generateCerts is ticked this is the name of the generated certificate
  certificateSecretName:
  #
  # settings for how Docker images are pulled
  image:
    # repository is the container repository to use, which must contain the IBM Event Streams images
    repository: cp.icr.io/cp/icp4i/es
    # pullSecret is the secret to use when pulling the image from a private registry
    #  optional when pulling from Docker registries that don't require authentication
    pullSecret:
    # pullPolicy is either IfNotPresent or Always
    #  (https://kubernetes.io/docs/concepts/containers/images/)
    pullPolicy: IfNotPresent
    imageTags:
      accessControllerTag: 2019-10-02-12.47.35-06feb68
      avroTag: 2019-10-02-12.55.11-89d5273
      certGenTag: 2019-10-18-13.37.59-44ba95f
      clientauthProxyTag: 2019-10-24-08.37.35-cfaad05
      codegenTag: 2019-10-07-11.59.12-94d44a9
      collectorTag: 2019-10-24-08.04.08-2175053
      databaseTag: 2019-10-14-13.15.56-ae55f14
      elasticSearchTag: 2019-10-08-10.41.35-cbba720
      healthcheckTag: 2019-10-04-11.23.39-efbaaff
      indexmgrTag: 2019-10-24-08.03.42-0b621c9
      initTag: 2019-10-02-12.50.47-444ce45
      kafkaMetricsProxyTag: 2019-10-24-08.05.52-ec3e36f
      kafkaProxyTag: 2019-10-24-08.05.25-d6fcc08
      kafkaTag: 2019-10-02-12.55.52-095ae1e
      kubectlTag: 2019-10-02-10.57.46-0c6b156
      metricsReporterTag: 2019-10-02-12.51.42-3d020d0
      oauthTag: 2019-10-02-12.56.11-6ea1927
      proxyTag: 2019-10-24-08.04.41-a2da90f
      registryTag: 2019-10-03-13.51.13-aae2eaf
      replicatorTag: 2019-10-02-12.57.32-77e5891
      restProducerTag: 2019-10-02-12.50.14-96affce
      restProxyTag: 2019-10-02-12.53.42-f20b201
      restTag: 2019-10-15-21.41.32-328aa25-dev
      roleMappingsTag: 2019-10-02-12.59.12-525ef93
      telemetryTag: 2019-10-02-12.52.26-e714065
      uiTag: 2019-10-09-16.08.45-ac12cd0
      vanillaTag: 2019-10-02-12.53.11-9ad6978
      zookeeperTag: 2019-10-02-12.53.22-8edf978
      

  # gid for the secondary group the containers should run in so that they can access NFS storage.
  fsGroupGid:
  # Architecture of worker nodes that IBM Event Streams will be deployed to
  arch: amd64

  security:
    # A flag to enable/disable all internal TLS endpoints.
    tlsInternal: "disabled"
    # icp cluster port
    managementIngressPort: 443
    # Certificate labels - initialized with a unique string
    # Change these strings on upgrade to regenerate certs
    externalCertificateLabel: "external-cert-initial-id"
    internalCertificateLabel: "internal-cert-initial-id"
    uiCertificateLabel: "ui-cert-initial-id"
  # settings for kubernetes level configuration which will affect multiple components
  k8s:
    # Allow the kubernetes internal DNS name to be configured
    clusterName: "cluster.local"
    # kubernetes api port
    apiPort: 2040

  zones:
    # Number of Zones
    count: 1
    # safe set to true to stop unsafe multi-zone
    safe: true
    # List of zone labels, if non zone-aware cluster
    labels: ["my-zone-label"]
    # the key for the zone label
    apiLabel: "failure-domain.beta.kubernetes.io/zone"
    # Zookeeper label for mapping zk to specific nodes
    zooKeeperLabel: "node-role.kubernetes.io/zk"
    # kafka label for mapping kafka to specific nodes
    kafkaLabel: "node-role.kubernetes.io/kafka"
    # Access controller Replicas for each zone
    accessControllerReplicas: 1
    # Rest Proxy Replicas for each zone
    restProxyReplicas: 1
    # Rest Producer Replicas for each zone
    restProducerReplicas: 1
    # Rest Replicas for each zone
    restReplicas: 1
    # Proxy Replicas for each zone
    proxyReplicas: 1

  generateClusterRoles: false

  resources:
    accessController:
      requests:
        cpu: 300m
        memory: 250Mi
      limits:
        cpu: 300m
        memory: 250Mi
    codegen:
      requests:
        cpu: 200m
        memory: 300Mi
      limits:
        cpu: 500m
        memory: 500Mi
    collector:
      requests:
        cpu: 100m
        memory: 50Mi
      limits:
        cpu: 100m
        memory: 50Mi
    database:
      requests:
        cpu: 100m
        memory: 100Mi
      limits:
        cpu: 100m
        memory: 100Mi
    indexManager:
      requests:
        cpu: 200m
        memory: 100Mi
      limits:
        cpu: 200m
        memory: 100Mi
    proxy:
      requests:
        cpu: 1000m
        memory: 100Mi
      limits:
        cpu: 1000m
        memory: 100Mi
    rest:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 4000m
        memory: 1Gi
    restProducer:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 4000m
        memory: 2Gi
    restProxy:
      requests:
        cpu: 500m
        memory: 250Mi
      limits:
        cpu: 500m
        memory: 250Mi
    # Used for all tls proxy containers except the proxy in the Kafka pod which has
    # specific resource requests/limits
    tlsProxy:
      requests:
        cpu: 100m
        memory: 100Mi
      limits:
        cpu: 100m
        memory: 100Mi
    ui:
      requests:
        cpu: 1000m
        memory: 1Gi
      limits:
        cpu: 1000m
        memory: 1Gi
###############################################################################
# ICP4I configuration
###############################################################################
icp4i:
  # The namespace that the ICP4I Platform Navigator has been installed into
  icp4iPlatformNamespace:

###############################################################################
# Dashboard configuration
###############################################################################
# must be enabled for dashboard to be deployed (true for ICP4I)
dashboard:
  enabled: true


###############################################################################
# Telemetry configuration
###############################################################################
# must be set to 'enable' for install to be tracked
telemetry:
  enabled: false

###############################################################################
# Kafka configuration
###############################################################################
kafka:
  # resource limits to apply to the Kafka broker containers
  # ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources:
    requests:
      cpu: 1000m
      memory: 2Gi
    limits:
      cpu: 1000m
      memory: 2Gi
  # resource limits to apply to the Kafka metrics-reporter containers
  metricsReporterResources:
    requests:
      cpu: 400m
      memory: 1500Mi
    limits:
      cpu: 600m
      memory: 1500Mi
  # resource limits to apply to the Kafka healthcheck containers
  healthcheckResources:
    requests:
      cpu: 200m
      memory: 100Mi
    limits:
      cpu: 200m
      memory: 100Mi
  # resource limits to apply to the Kafka metrics-proxy containers
  metricsProxyResources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 500m
      memory: 1Gi
  # resource limits to apply to the Kafka tls-proxy containers
  tlsProxyResources:
    requests:
      cpu: 100m
      memory: 100Mi
    limits:
      cpu: 500m
      memory: 100Mi

  # Number of Kafka brokers in the cluster
  brokers: 3
  # Name of configmap containing equivalent key=value to kafka's server.properties
  configMapName: ""
  # Any extra arguments to pass to the JVM when running Kafka brokers
  heapOpts: "-XX:+UseContainerSupport"
  # Whether to open kafka to JMX connections from cluster
  openJMX: false

#
# Persistence settings which apply to the Kafka broker pods
persistence:
  # whether to use Persistent Volumes for the Kafka pods
  enabled: false
  # whether to use Storage Classes to dynamically create Persistent Volumes for the Kafka pods
  useDynamicProvisioning: false
  #
  # settings for the Kafka pod Persistent Volume Claims,
  #   which each pod uses for data in /var/data
  dataPVC:
    # prefix for names for this Persistent Volume Claim
    name: "datadir"
    # name of the Storage Class to use, or an empty string for no Storage Class
    storageClassName: ""
    # minimum size of the Persistent Volume
    size: 4Gi



###############################################################################
# ZooKeeper configuration
###############################################################################
zookeeper:
  # resource limits to apply to the ZooKeeper pods
  # ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources:
    requests:
      cpu: 100m
      memory: 750Mi
    limits:
      cpu: 100m
      memory: 1Gi

  #
  # Persistence settings which apply to the ZooKeeper pods
  persistence:
    # whether to use Persistent Volumes for the ZooKeeper pods
    enabled: false
    # whether to use Storage Classes to dynamically create Persistent Volumes for the ZooKeeper pods
    useDynamicProvisioning: false

  #
  # settings for the ZooKeeper Persistent Volume Claims
  #  which each pod uses for data in /var/lib/zookeeper
  dataPVC:
    # prefix for names for this Persistent Volume Claim
    name: "datadir"
    # name of the Storage Class to use, or an empty string for no Storage Class
    storageClassName: ""
    # minimum size of the Persistent Volume
    size: 2Gi



###############################################################################
# Kafka external access configuration
###############################################################################
proxy:
  # external IP address for access that the proxy should use
  # Domain for routes can be found in OCP 4.x using the command
  # oc get --namespace=openshift-ingress-operator ingresscontroller/default -o yaml | grep "domain: " | tr -d ' ' | cut -d ':' -f2
  externalEndpoint: ""
  upgradeToRoutes: false

# Secure connection settings for the proxy
tls:
  type: "selfsigned"
  # Name of the secret to read the provided certificates from
  secretName:
  # These values are retained for upgrade purposes but are hidden in the UI
  key:
  cert:
  cacert:

###############################################################################
# Message Indexing configuration
###############################################################################
messageIndexing:
  # Whether to enable indexing of messages to enhance viewing
  messageIndexingEnabled: true
  # Resource limits for elastic search containers
  resources:
    requests:
      cpu: 500m
      memory: 2Gi
    limits:
      cpu: 1000m
      memory: 4Gi
###############################################################################
# Geo-replicator configuration
###############################################################################
replicator:
  replicas: 0
  # resource requests/limits to apply to the geo-replicator replicator containers
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1000m
      memory: 1Gi
  # resource requests/limits to apply to the geo-replicator metrics-reporter containers
  metricsReporterResources:
    requests:
      cpu: 400m
      memory: 1500Mi
    limits:
      cpu: 600m
      memory: 1500Mi

###############################################################################
# Schema Registry Configuration
###############################################################################
schema-registry:
  #
  # Persistence settings for the Schema Registry API server pods
  persistence:
    # whether to use Persistent Volumes for the Schema Registry API server pods
    enabled: false
    # whether to use Storage Classes to dynamically create Persistent Volumes for the Schema Registry pods
    useDynamicProvisioning: false
    # Storage mode
    mode: "ReadWriteMany"
  resources:
    requests:
      cpu: 500m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 256Mi
  avroServiceResources:
    requests:
      cpu: 500m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 256Mi

  #
  # settings for the Schema Registry Persistent Volume Claims
  #  which each pod uses for data in /var/lib/schemas
  dataPVC:
    # prefix for names for this Persistent Volume Claim
    name: "datadir"
    # name of the Storage Class to use, or an empty string for no Storage Class
    storageClassName: ""
    # minimum size of the Persistent Volume
    size: 100Mi
  #
  # Schema registry pod replicas
  # Value replaced in template with default values if not changed on install
  replicas: 0

###############################################################################
# External monitoring configuration
###############################################################################
externalMonitoring:
  datadog: {}

###############################################################################
# Check chart is being installed on a supported platform
# If this is set to false you could be installing an unsupported version of Event Streams
###############################################################################
checkSupportedPlatform: true

###############################################################################
# license must be set to "accept" to accept the terms of the IBM license
###############################################################################
license: "not_accepted"
