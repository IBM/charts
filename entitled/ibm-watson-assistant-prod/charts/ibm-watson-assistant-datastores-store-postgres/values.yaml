global:
  postgres:
    auth:
      # global.postgres.auth.authSecretName - Name of the (manually created) secret that holds the password (key: `password`) for postgres superuser specified in global.`postgres.auth.user`. If empty the secrets is autogenerated with randomly generated password.
      authSecretName: ""
    
    # global.postgres.sslSecretName - Name of the manually (created) secret that holds the certificate (key `tls.crt`) and if not `global.postgres.create` is true then also private key for the certificate (key `tls.key`)
    # If the global.postgres.create is `false` (i.e., provide your own postgres, you describe provided postgres instance, if the valu is true, you provides cert/key pair to be used by postgres installed by the this chart.
    sslSecretName: ""
  
  image:
    repository: ""

creds:
  image:
    repository: "{{ tpl .Values.global.image.repository . }}"
    name:       "conan-tools"
    tag:        "20190809-0011"
    pullPolicy: "IfNotPresent"

config:
  # config.nameOverride - Do not even think about changing this value
  nameOverride: store-postgres
  
  clusterName: "{{ .Release.Name }}"
  auth:
    pgSuperuserName: "{{ .Values.global.postgres.auth.user }}"
    authSecretName: '{{ include "assistant.postgres.secret_name" . }}'

  tls:
    enabled: true
    tlsSecretName: '{{ include "assistant.postgres.secret_name" . }}'

  persistence:
    # enabled - Data stre stored persistenly. Not to loose the data if pod is deleted/restarted
    enabled: true
    
    # storageClassName - set to null to use the default storageClassName
    # Note that glusterfs is not recommended (poor performance, stability???) of postgres 
    storageClassName: null
    
    #size - size of PVC
    #size: 10Gi
  dataPVC:
    name: pg
  
  keep: "{{ .Values.global.keepDatastores }}"

  proxy:
    serviceType: ""
    resources:
      requests:
        cpu: "10m"
        memory: "64Mi"
      limits:
        # cpu limits removed for WA ICP deployments
        memory: "64Mi"
    affinity:
      nodeAffinity:    '{{ include "assistant.ibm-postgres.proxy.affinity.nodeAffinity"    . }}'
      podAntiAffinity: '{{ include "assistant.ibm-postgres.proxy.affinity.podAntiAffinity" . }}'

    # Enabling pod disruption budget
    podDisruptionBudget:
      maxUnavailable: 1
    
  sentinel:
    resources:
      requests:
        cpu: "40m"
        memory: "64Mi"
      limits:
        # cpu limits removed for WA ICP deployments
        memory: "64Mi"
    affinity:
      nodeAffinity:    '{{ include "assistant.ibm-postgres.sentinel.affinity.nodeAffinity"    . }}'
      podAntiAffinity: '{{ include "assistant.ibm-postgres.sentinel.affinity.podAntiAffinity" . }}'

    # Enabling pod disruption budget
    podDisruptionBudget:
      maxUnavailable: 1
  
  keeper:
    resources:
      requests:
        cpu: "50m"
        memory: "512Mi"
      limits:
        # cpu limits removed for WA ICP deployments
        memory: "512Mi"
    affinity:
      nodeAffinity:    '{{ include "assistant.ibm-postgres.keeper.affinity.nodeAffinity"    . }}'
      podAntiAffinity: '{{ include "assistant.ibm-postgres.keeper.affinity.podAntiAffinity" . }}'

    # Enabling pod disruption budget
    podDisruptionBudget:
      maxUnavailable: 1

  metering:
    productName:    "IBM Watson Assistant for IBM Cloud Private for Data"
    productID:      "ICP4D-addon-53256faf537b4d4d956f0c5a24d78b08-assistant"
    productVersion: "1.3.0"  

# The suffix of all the cluster DNS names like service_name.service_namespace.svc.cluster.local
#clusterDomain: "cluster.local"
clusterDomain: "{{ tpl .Values.global.clusterDomain . }}"
