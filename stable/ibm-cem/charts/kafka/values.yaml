# This is a YAML-formatted file
# Declare name/value pair to be passed into you templates

arch:   # list of supported arch s390x ppc64le amd64
  - amd64

global:
  environmentSize: "size0"
  persistence:
    enabled: true
    supplementalGroups:     # this is required for NFS storage
      # - 1001              # - provide the gid of the volumes as list
      # - 1002
    storageSize:
      kafkadata: 512Mi
    storageClassName: ""
    storageClassOption:
      kafkadata: "default"
  ssl:
    keystorePassword: "abcdefgh"
    truststorePassword: "abcdefgh"
    password: "abcdefgh"
  image:
    repository: ""
  kafka:
    clusterSize:
image:
  tag: "HDM_201812061912"
  pullPolicy: IfNotPresent
# config/kafka.yaml values must be changed to match

# Option to configure additional listener hostnames
# These should be externally accessible names (preferred) or addresses.
# You'll need to provide a list for as many instances of Kafka you are running
# OR allow access via a single proxy but separated by NodePorts.
advertisedListeners:
  # - host1.acme.com    # name for kafka-0
  # - host2.acme.com    # name for kafka-1
  # - host3.acme.com    # name for kafka-2  etc.

clusterSize: 1
defaultTopicPartitions: 6
offsetsTopicReplicationFactor: 1
minInsyncReplicas: 1

ssl:
  enabled: false
  allowInsecure: true
  secret: "winterfell-trust"
client:
  username: "alice"
  password: "alice-secret"
admin:
  username: "admin"
  password: "admin-secret"

###
# Kafka Rest Support
###
kafkarest:
  enabled: true
  # this option effectively runs the container as root
  # so the old ports 80/443 can continue to run
  enablePrivilegedPorts: false
  image:
    tag: "HDM_201812061912"
    pullPolicy: IfNotPresent
