{{- include "sch.config.init" (list . "db2oltp.sch.chart.config.values") -}}
apiVersion: v1
kind: Service
metadata:
  name: {{ template "fullname" . }}
  labels:
    app: {{ template "fullname" . }}
    chart: "{{ .Chart.Name }}"
    component: "db2"
    release: "{{ .Release.Name }}"
    heritage: "{{ .Release.Service }}"
spec:
  ports:
  - port: 50000
    name: main
    targetPort: 50000
    protocol: TCP
  - port: 55000
    name: text
    targetPort: 55000
    protocol: TCP
  - port: 60006
    name: db2hadrp
    targetPort: 60006
    protocol: TCP
  - port: 60007
    name: db2hadrs
    targetPort: 60007
    protocol: TCP
  clusterIP: None
  selector:
    app: {{ template "fullname" . }}
    component: "db2"
---

{{- if semverCompare ">=1.11.1" .Capabilities.KubeVersion.GitVersion }}
apiVersion: apps/v1
{{- else if .Capabilities.APIVersions.Has "apps/v1beta2" }}
apiVersion: apps/v1beta2
{{- else }}
apiVersion: apps/v1beta1
{{- end }}
kind: StatefulSet
metadata:
  name: {{ template "fullname" . }}
  labels:
    app: {{ template "fullname" . }}
    chart: "{{ .Chart.Name }}"
    component: "db2"
    release: "{{ .Release.Name }}"
    heritage: "{{ .Release.Service }}"
spec:
  selector:
    matchLabels:
      app: {{ template "fullname" . }}
      release: {{ .Release.Name }}
      heritage: {{ .Release.Service }}
      component: "db2"
  serviceName: {{ template "fullname" . }}
{{- if .Values.hadr.enabled }}  
  podManagementPolicy: "Parallel"
  replicas: 2
{{- else }}
  replicas: 1
{{- end }}
  {{- if and (.Capabilities.KubeVersion.Major | hasPrefix "1") (.Capabilities.KubeVersion.Minor | hasPrefix "7") }}
  # Set updateStrategy to "RollingUpdate", if we're on Kubernetes 1.7.
  # It's already the default for apps/v1beta2 (Kubernetes 1.8 onwards)
  updateStrategy:
    type: OnDelete
  {{- end }}
  template:
    metadata:
      name: {{ template "fullname" . }}
      labels:
        app: {{ template "fullname" . }}
        chart: "{{ .Chart.Name }}"
        component: "db2"
        release: "{{ .Release.Name }}"
        heritage: "{{ .Release.Service }}"
      annotations:
        {{- include "sch.metadata.annotations.metering" (list . .sch.chart.metering) | indent 8 }}
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          #If you specify multiple nodeSelectorTerms associated with nodeAffinity types, 
          #then the pod can be scheduled onto a node if one of the nodeSelectorTerms is satisfied.
          #
          #If you specify multiple matchExpressions associated with nodeSelectorTerms, 
          #then the pod can be scheduled onto a node only if all matchExpressions can be satisfied.
          #
          #valid operators: In, NotIn, Exists, DoesNotExist, Gt, Lt
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                {{- if .Values.arch }}
                - {{ .Values.arch }}
                {{- else }}
                - {{ template "arch" . }}
                {{- end }}
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app: "{{ template "fullname" . }}"
                  release: "{{ .Release.Name }}"
                  component: "db2"
      volumes:
      - name: {{ template "datastorname" . }}
      {{- if and (.Values.persistence.enabled) (not .Values.hadr.enabled) }}
        persistentVolumeClaim:
        {{- if .Values.dataVolume.existingClaimName }}
          claimName: {{ .Values.dataVolume.existingClaimName }}
        {{- else }}
          claimName: {{ template "datastorname" . }}
        {{- end }}
      {{- else }}
        emptyDir: {}
      {{- end }}
      - name: {{ template "hadrstorname" . }}
      {{- if and (.Values.persistence.enabled) (.Values.hadr.enabled) }}
        persistentVolumeClaim:
        {{- if .Values.hadrVolume.existingClaimName }}
          claimName: {{ .Values.hadrVolume.existingClaimName }}
        {{- else }}
          claimName: {{ template "hadrstorname" . }}
        {{- end }}
      {{- else }}
        emptyDir: {}
      {{- end }}
      - name: cgvol
        hostPath:
          path: /sys/fs/cgroup
      - name: sys
        hostPath:
          path: /proc/sys
      - name: proc
        hostPath:
          path: /proc
      hostNetwork: false
      hostPID: false
      hostIPC: true
      initContainers:
        - name: init-db2
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}{{ template "platform" . }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command: ['sh','-c','/var/db2_setup/lib/set_kernel_params.sh']
          volumeMounts:
          - name: proc
            mountPath: /host/proc
            readOnly:  false
          - name: sys
            mountPath: /host/proc/sys
            readOnly: false
      containers:
      - name: {{ template "fullname" . }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}{{ template "platform" . }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        securityContext:
          runAsNonRoot: false
          runAsUser: 0
          capabilities:
            drop:
            - ALL
            #Need the default Docker capabilities. Additional ones are "SYS_RESOURCE", "IPC_OWNER", "SYS_NICE"
            add: ["SYS_RESOURCE", "IPC_OWNER", "SYS_NICE", "SETPCAP", "CHOWN", "FOWNER", "NET_RAW", "DAC_OVERRIDE", "FSETID", "KILL", "SETGID", "SETUID", "MKNOD", "AUDIT_WRITE", "SYS_CHROOT", "NET_BIND_SERVICE", "SETFCAP"]
          allowPrivilegeEscalation: true
          readOnlyRootFilesystem: false
          privileged: false
        ports:
        - containerPort: 50000
        - containerPort: 55000
        env:
        - name: LICENSE
          value: "accept"
        - name: DB2INSTANCE
          value: {{ default "db2inst1" .Values.db2inst.instname | quote }}
        - name: DB2INST1_PASSWORD
          valueFrom:
            secretKeyRef:
              name: {{ template "fullname" . }}
              key: password 
      {{- if not .Values.hadr.enabled }}
        - name: DBNAME
          value: "{{ .Values.options.databaseName }}"
      {{- else }}
        - name: DBNAME
          value: {{ default "sample" .Values.options.databaseName| quote }}
      {{- end }} 
        - name: BLU
          value: "false"
        - name: ENABLE_ORACLE_COMPATIBILITY
          value: "{{ .Values.options.oracleCompatibility }}"
        - name: UPDATEAVAIL
          value: "NO"
        - name: ETCD_ENDPOINT
          value: "http://{{ template "fullname" . }}-etcd-0.{{ template "fullname" . }}-etcd:2379,http://{{ template "fullname" . }}-etcd-1.{{ template "fullname" . }}-etcd:2379,http://{{ template "fullname" . }}-etcd-2.{{ template "fullname" . }}-etcd:2379"
        - name: TO_CREATE_SAMPLEDB
          value: "false" 
        - name: IS_OSXFS
          value: "false"
        - name: REPODB
          value: "false"
        - name: HADR_ENABLED
          value: "{{ .Values.hadr.enabled }}"
        - name: IS_KUBE
          value: "true"
         #set liveness probe to determine if container needs to be restarted
         #- command, http, or tcp
         #ref : https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - su - $DB2INSTANCE  -c '/database/config/$DB2INSTANCE/sqllib/bin/db2gcf -s'
        {{- if not .Values.hadr.enabled }}
          initialDelaySeconds: 810
        {{- else }}
          initialDelaySeconds: 1620
        {{- end }}
          periodSeconds: 90
          failureThreshold: 3 
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - su - $DB2INSTANCE  -c '/database/config/$DB2INSTANCE/sqllib/bin/db2gcf -s'
        {{- if not .Values.hadr.enabled }}
          initialDelaySeconds: 60
        {{- else }}
          initialDelaySeconds: 360
        {{- end }}
          periodSeconds: 30
          failureThreshold: 50
        resources:
{{ toYaml .Values.resources | indent 10 }}
        volumeMounts:
        - mountPath: /sys/fs/cgroup
          name: cgvol
          readOnly: true
        - mountPath: /database
        {{- if .Values.hadr.enabled }}
          name: {{ .Values.dataVolume.name | quote }}
        {{- else }}
          name: {{ template "datastorname" . }}
        {{- end }}
        - mountPath: /hadr
          name: {{ template "hadrstorname" . }}
{{- if .Values.global.image.secretName }}
      imagePullSecrets:
          - name: {{ .Values.global.image.secretName }}
{{- end }}
  volumeClaimTemplates:
  {{- if and (.Values.persistence.enabled) ( .Values.hadr.enabled) (not .Values.dataVolume.existingClaimName) }}
  - metadata:
      name: {{ .Values.dataVolume.name | quote }}
      labels:
        app: {{ template "fullname" . }}
        chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
        component: "db2"
        release: "{{ .Release.Name }}"
        heritage: "{{ .Release.Service }}"
    spec:
      {{- if .Values.persistence.useDynamicProvisioning }}
      # If present, use the storageClassName from the values.yaml, else use the
      # default storageClass setup by Kubernetes Administrator
      #
      # Setting storageClassName to nil means use the default storage class
      storageClassName: {{ default nil .Values.dataVolume.storageClassName | quote }}
      {{- else }}
      storageClassName: {{ default "" .Values.dataVolume.storageClassName | quote }}
      {{- end }}
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: {{ .Values.dataVolume.size | quote }}
  {{- end }}





