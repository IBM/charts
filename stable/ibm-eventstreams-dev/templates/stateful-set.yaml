###############################################################################
#
# Licensed Materials - Property of IBM
#
# (C) Copyright IBM Corp. 2018. All Rights Reserved.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
###############################################################################
# Defines the Kubernetes pods that will make up the cluster of Kafka brokers
###############################################################################
{{ if eq .Values.license "accept" -}}
{{ $zookeeperConfig := include "sch.config.init" (list . "zookeeper.sch.chart.config.values" ) -}}
{{ $securityConfig := include "sch.config.init" (list . "security.sch.chart.config.values") -}}
{{ $namePrefix := .sch.chart.components.kafka.statefulSet.name -}}
{{ $statefulSetName := include "sch.names.statefulSetName" (list . $namePrefix) -}}
# Component is 'kafka' as this makes up part of implementing the Kafka cluster
{{ $compName := .sch.chart.components.kafka.compName -}}
{{ $labels := include "sch.metadata.labels.standard" (list . $compName (dict "serviceSelector" $namePrefix)) -}}
# The headless service that will provide access to the Kafka brokers defined below
{{ $serviceName := .sch.chart.components.kafka.headless.name -}}
# Name of the ZooKeeper stateful deployment that will orchestrate the Kafka brokers
{{ $zookeeperName := .sch.chart.components.zookeeper.statefulSet.name -}}
# Services allowing access to individual ZooKeeper nodes - there will be one of these for each node
{{ $zookeeperFixedIPService := .sch.chart.components.zookeeper.fixed.name -}}
{{ $zookeeperFixedIPServiceName := include "sch.names.fullCompName" (list . $zookeeperFixedIPService) -}}
# Name of ZooKeeper headless service
{{ $zookeeperHeadlessService := .sch.chart.components.zookeeper.headless.name -}}
{{ $zookeeperHeadlessServiceName := include "sch.names.fullCompName" (list . $zookeeperHeadlessService ) -}}
# number of ZooKeeper nodes in the cluster
{{ $zookeeperReplicas := int .sch.config.zookeeper.replicas -}}
# Config map that identifies the metrics that should be pushed to Prometheus
{{ $kafkaMetricsConfigMap := .sch.chart.components.kafka.metricsConfigMap.name -}}
{{ $kafkaMetricsConfigMapName := include "sch.names.fullCompName" (list . $kafkaMetricsConfigMap) | quote -}}
# Service Account to grant Kubernetes access
{{ $serviceAccount := .sch.chart.components.kafka.serviceAccount.name -}}
{{ $serviceAccountName := include "sch.names.fullCompName" (list . $serviceAccount ) -}}
# Kafka ports are defined in a helper template
{{ $kafkaconfig := include "sch.config.init" (list . "kafka.listeners.sch.chart.config.values") -}}
{{ $kafkaListeners := .sch.config.kafka.listeners -}}
{{ $kafkaProtocols := .sch.config.kafka.protocols -}}
{{ $kafkaAdvertisedListeners := .sch.config.kafka.internalAdvertisedListeners -}}
# Index manager service name required by kafka-metrics-proxy
{{ $indexmgrService := .sch.chart.components.indexmgr.service.name -}}
{{ $indexmgrServiceName := include "sch.names.fullCompName" (list . $indexmgrService) -}}
# Elastic search service name required by kafka-metrics-proxy
{{ $elasticSearchService := .sch.chart.components.elasticSearch.service.name -}}
{{ $elasticSearchServiceName := include "sch.names.fullCompName" (list . $elasticSearchService) -}}
# import port definitions
{{- include "sch.config.init" (list . "ports.sch.chart.config.values") | trim -}}
{{ $ports := .sch.config.ports }}
# Oauth secret name which is used to get the cluster name
{{ $uiOauthSecretName := .sch.chart.components.ui.oauthSecret.name -}}
{{ $oauthSecretName := include "sch.names.fullCompName" (list . $uiOauthSecretName) -}}
# IAM Secret name containing the API Key
{{ $iamSecret := .sch.chart.components.security.iamSecret.name -}}
{{ $iamSecretName := include "sch.names.fullCompName" (list . $iamSecret ) -}}
# Eventstreams IAM Service Name
{{ $iamServiceName := .sch.chart.components.security.serviceName -}}
# Access controller service that we need to connect to do IAM Authorisations
{{ $accessControllerService := .sch.chart.components.security.accesscontroller.service.name -}}
{{ $accessControllerServiceName := include "sch.names.fullCompName" (list . $accessControllerService) -}}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $statefulSetName | quote }}
  namespace: {{ include "restrict.namespace" (list . .Release.Namespace) }}
  labels:
{{ $labels | indent 4 }}
spec:
  # identify the headless service that will enable access to these pods
  serviceName: {{ include "sch.names.fullCompName" (list . $serviceName) | quote }}
  # Kafka pods are deployed in parallel to enable faster deployments
  podManagementPolicy: "Parallel"
  # the number of brokers in the kafka cluster
  {{- if regexMatch "(^[3-9]+[0-9]*$)|(^[1-9]+[0-9]+$)" (.Values.kafka.brokers | toString) }}
  replicas: {{ .Values.kafka.brokers }}
  {{- else }}
  {{ fail "Configuration error: Minimum of 3 Kafka brokers required." }}
  {{- end }}
  # Kafka broker pods are uniquely identified based on the release name
  selector:
    matchLabels:
      release: {{ .Release.Name | quote }}
      serviceSelector: {{ $namePrefix | quote }}
  updateStrategy:
    type: RollingUpdate
  # definition of the pods that run the Kafka brokers in the cluster
  template:
    metadata:
      # Check release name is valid.
      {{- if regexMatch "^[a-z][a-z0-9-]*[a-z0-9]*$" .Release.Name }}
      name: {{ .Release.Name | quote }}
      {{- else }}
      {{ fail "Configuration error: Format of release name is invalid." }}
      {{- end }}
      # Check release name does not end with a dash.
      {{- if regexMatch "-$" .Release.Name }}
      {{ fail "Configuration error: Format of release name is invalid." }}
      {{- end }}
      namespace: {{ include "restrict.namespace" (list . .Release.Namespace) }}
      labels:
{{ $labels | indent 8 }}
        configMapRevision: "default"
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '{{ $ports.prometheus.collectorKafka }}'
{{ include "metering" (list . "kafka") | indent 8 }}
    spec:
      # # Hostname is kafka, used for internal pod communication
      # hostname: kafka
      serviceAccountName: {{ $serviceAccountName | quote }}
      {{- if .Values.global.image.pullSecret }}
      imagePullSecrets:
        - name: {{ .Values.global.image.pullSecret }}
      {{- end }}
      securityContext:
{{ include "fsGroupGid" (list . ) | indent 8 }}
      affinity:
      {{- include "customNodeaffinity" . | indent 6 }}
        # we don't want multiple co-located Kafka nodes
        #  so this anti-affinity rule should prevent
        #  nodes with the kafka name being scheduled on
        #  the same host
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: "release"
                      operator: In
                      values:
                        -  {{ .Release.Name | quote }}
                    - key: "serviceSelector"
                      operator: In
                      values:
                        -  {{ $namePrefix | quote }}
                topologyKey: "kubernetes.io/hostname"
        # colocating Kafka nodes with ZooKeeper nodes could
        #  help minimise network traffic between them, so
        #  this affinity rule requests this where possible
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
             - weight: 1
               podAffinityTerm:
                 labelSelector:
                    matchExpressions:
                      - key: "release"
                        operator: In
                        values:
                          -  {{ .Release.Name | quote }}
                      - key: "serviceSelector"
                        operator: In
                        values:
                          -  {{ $zookeeperName }}
                 topologyKey: "kubernetes.io/hostname"
      # Kafka pods are made up of four containers
      #  1) Kafka broker
      #  2) Metrics reporter that submits metrics from the Kafka broker to Prometheus
      #  3) Kafka metrics proxy, an interceptor that reads kafka protocol and pipes out metadata to elasticsearch
      #  4) Healthcheck
      containers:
        #
        # Kafka broker pods
        - name: kafka
          image: {{ include "eventstreams.image" (list . "eventstreams-kafka" .Values.global.image.imageTags.kafkaTag "true") | quote }}
          imagePullPolicy: {{ .Values.global.image.pullPolicy }}
          securityContext:
            privileged: false
            readOnlyRootFilesystem: false
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 65534
            capabilities:
              drop:
              - all
          resources:
            limits:
{{ toYaml .Values.kafka.resources.limits | indent 14 }}
            requests:
{{ toYaml .Values.kafka.resources.requests | indent 14 }}
          ports:
            - containerPort: {{ $ports.kafka.internalKafka }}
              name: "kafka"
            - containerPort: {{ $ports.kafka.externalSecure }}
              name: "ext-secure"
            - containerPort: {{ $ports.kafka.internalEventStreamsSecure }}
              name: "es-secure"
          readinessProbe:
            httpGet:
              port: {{ $ports.kafka.healthcheck }}
              path: /readiness
            initialDelaySeconds: 120
            periodSeconds: 15
            failureThreshold: 1
          livenessProbe:
            httpGet:
              port: {{ $ports.kafka.healthcheck }}
              path: /liveness
            initialDelaySeconds: 360
            periodSeconds: 15
            failureThreshold: 3
          env:
            {{- include "license.accept.env.ref" . | indent 10 }}
            - name: ZK_FIXED_IP_NAME
              value: {{ $zookeeperFixedIPServiceName }}
            - name: NAMESPACE
              value: {{ .Release.Namespace | quote }}
            - name: RELEASE
              value: {{ .Release.Name | quote }}
            - name: "CLUSTER_NAME"
              valueFrom:
                secretKeyRef:
                  name: {{ $oauthSecretName }}
                  key: "clusterName"
            - name: "ES_API_KEY"
              valueFrom:
                secretKeyRef:
                  name: "{{ $iamSecretName }}"
                  key: "{{ $iamServiceName }}-{{ $.Release.Name }}-api-key"
            - name: KAFKA_HEAP_OPTS
{{- if regexMatch "^[1-9][0-9]*[mg]$" .Values.kafka.jvmHeapSize }}
              value: "-Xmx{{ .Values.kafka.jvmHeapSize }} -Xms{{ .Values.kafka.jvmHeapSize }} {{ .Values.kafka.heapOpts }}"
{{- else }}
{{ fail "Configuration error: You have entered an invalid JVM heap limit for Kafka brokers. Please enter the value in '^[1-9][0-9]*[mg]$' format." }}
{{- end }}
            - name: KAFKA_LISTENERS
              value: {{ $kafkaListeners }}
            - name: LISTENER_SECURITY_PROTOCOL_MAP
              value: {{ $kafkaProtocols }}
            - name: ACCESS_CONTROLLER_HOSTNAME
              value: {{ $accessControllerServiceName }}
            - name: ACCESS_CONTROLLER_PORT
              value: {{ $ports.security.accessController | quote }}
            - name: ADVERTISED_LISTENERS
              value: {{ $kafkaAdvertisedListeners }}
            - name: INTER_BROKER_PROTOCOL_VERSION
              value: {{ .Values.kafka.interBrokerProtocolVersion | quote }}
            - name: LOG_MESSAGE_FORMAT_VERSION
              value: {{ .Values.kafka.logMessageFormatVersion | quote }}
            - name: BROKER_LOGGING_LEVEL
              value: {{ .Values.kafka.brokerLoggingLevel | quote }}
          volumeMounts:
          {{- if .Values.kafka.configMapName }}
            - name: cluster-config-volume
              mountPath: /opt/cluster-configmap
              readOnly: true
          {{- end }}
          {{- if .Values.persistence.enabled }}
            - name: {{ .Values.persistence.dataPVC.name }}
              mountPath: /var/data
          {{- else }}
            - name: "tempdir"
              mountPath: /var/data
          {{- end }}
        #
        # Metrics reporter sidecar - receives Kafka metrics and pushes to Prometheus
        - name: metrics-reporter
          image: {{ include "eventstreams.image" (list . "eventstreams-kafka-metrics-reporter" .Values.global.image.imageTags.metricsReporterTag "true") | quote }}
          imagePullPolicy: {{ .Values.global.image.pullPolicy }}
          securityContext:
            privileged: false
            readOnlyRootFilesystem: false
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
            capabilities:
              drop:
              - all
          resources:
            limits:
{{ toYaml .Values.kafka.metricsReporterResources.limits | indent 14 }}
            requests:
{{ toYaml .Values.kafka.metricsReporterResources.requests | indent 14 }}
          env:
            {{- include "license.accept.env.ref" . | indent 10 }}
            - name: NAMESPACE
              value: {{ $.Release.Namespace }}
            - name: METRICS_PORT
              value: "{{ $ports.kafka.metrics }}"
            - name: IBM_JAVA_OPTIONS
{{- if regexMatch "^[1-9][0-9]*[mg]$" .Values.kafka.metricsReporterJvmHeapSize }}
              value: "-Xmx{{ .Values.kafka.metricsReporterJvmHeapSize }} -Xms{{ .Values.kafka.metricsReporterJvmHeapSize }}"
{{- else }}
{{ fail "Configuration error: You have entered an invalid JVM heap limit for metrics reporters. Please enter the value in '^[1-9][0-9]*[mg]$' format." }}
{{- end }}
          ports:
            - containerPort: {{ $ports.kafka.metrics }}
              name: metrics-port
          readinessProbe:
            timeoutSeconds: 30
            periodSeconds: 30
            initialDelaySeconds: 90
            failureThreshold: 100
            httpGet:
              port: {{ $ports.kafka.metrics }}
              path: /metrics
          livenessProbe:
            timeoutSeconds: 30
            periodSeconds: 30
            initialDelaySeconds: 120
            failureThreshold: 100
            tcpSocket:
              port: {{ $ports.kafka.metrics }}
          volumeMounts:
            - name: metrics-config-volume
              mountPath: /etc/kafka-metrics-reporter
        #
        # Metrics proxy sidecar - interprets Kafka traffic metrics from the protocol and pushes to the index manager
        - name: metrics-proxy
          image: {{ include "eventstreams.image" (list . "eventstreams-kafka-metrics-proxy" .Values.global.image.imageTags.kafkaMetricsProxyTag "true") | quote }}
          imagePullPolicy: {{ .Values.global.image.pullPolicy }}
          securityContext:
            privileged: false
            readOnlyRootFilesystem: true
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
            capabilities:
              drop:
              - all
          env:
            {{- include "license.accept.env.ref" . | indent 10 }}
            - name: ES_PROXY_CONFIG
              value: |-
                {
                  "routes": "[{\"port\":{{ $ports.kafka.externalProxySecure }}, \"service\": \"localhost:{{ $ports.kafka.externalSecure }}\"}, {\"port\":{{ $ports.kafka.internalEventStreamsSecureIntercept }}, \"service\": \"localhost:{{ $ports.kafka.internalEventStreamsSecure }}\"}]",
                  "tlsEnabled": "false",
                  "updateURL": "http://{{ $indexmgrServiceName }}:{{ $ports.indexmgr.metrics }}/update",
                  "deletionURL": "http://{{ $indexmgrServiceName }}:{{ $ports.indexmgr.metrics }}/topicDelete",
                  "connectionTimeoutMs": "3600000",
                  "traceLevel": "0",
                  "logFormat": "json"
                }
          ports:
            - containerPort: {{ $ports.kafka.externalProxySecure }}
              name: external
            - containerPort: {{ $ports.kafka.internalEventStreamsSecureIntercept }}
              name: internal
            - containerPort: {{ $ports.proxy.health }}
              name: proxy-health
          readinessProbe:
            httpGet:
              path: "/ready"
              port: {{ $ports.proxy.health }}
            initialDelaySeconds: 1
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: "/live"
              port: {{ $ports.proxy.health }}
            initialDelaySeconds: 15
            periodSeconds: 15
        #
        # Healthcheck container
        - name: healthcheck
          image: {{ include "eventstreams.image" (list . "eventstreams-healthcheck" .Values.global.image.imageTags.healthcheckTag "true") | quote }}
          imagePullPolicy: {{ .Values.global.image.pullPolicy }}
          securityContext:
            privileged: false
            readOnlyRootFilesystem: true
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
            capabilities:
              drop:
              - all
          ports:
            - containerPort: {{ $ports.kafka.healthcheck }}
              name: hc-port
          env:
            {{- include "license.accept.env.ref" . | indent 10 }}
            - name: NAMESPACE
              value: {{ .Release.Namespace | quote }}
            - name: ZOOKEEPER_CONNECT
              value: '{{ range $index, $_ := until $zookeeperReplicas }}{{if $index}},{{end}}{{ $zookeeperFixedIPServiceName }}-{{ $index }}:2181{{ end }}'
          readinessProbe:
            httpGet:
              port: {{ $ports.kafka.healthcheck }}
              path: /healthz
            initialDelaySeconds: 150
            periodSeconds: 15
            failureThreshold: 3
          livenessProbe:
            httpGet:
              port: {{ $ports.kafka.healthcheck }}
              path: /healthz
            initialDelaySeconds: 180
            periodSeconds: 15
            failureThreshold: 3
      volumes:
        - name: metrics-config-volume
          configMap:
            name: {{ $kafkaMetricsConfigMapName }}
        {{- if .Values.kafka.configMapName }}
        - name: cluster-config-volume
          configMap:
            name: {{ .Values.kafka.configMapName }}
        {{- end }}
        {{ if .Values.persistence.enabled -}}
        {{ else }}
        - name: "tempdir"
          emptyDir: {}
        {{ end }}
  {{ if .Values.persistence.enabled -}}
  volumeClaimTemplates:
    - metadata:
        name: {{include "sch.names.volumeClaimTemplateName" (list . .Values.persistence.dataPVC.name $statefulSetName)}}
        labels:
{{ $labels | indent 10 }}
      spec:
        {{ if .Values.persistence.useDynamicProvisioning -}}
        # If present, use the storageClassName from the values.yaml, else use the
        # default storageClass setup by Kubernetes Administrator
        #
        # Setting storageClassName to nil means use the default storage class
        storageClassName: {{ default nil .Values.persistence.dataPVC.storageClassName | quote }}
        {{ else -}}
        # Disable dynamic provisioning
        storageClassName: ""
        {{ end -}}
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: {{ .Values.persistence.dataPVC.size | quote }}
  {{ end -}}
{{ end -}}
